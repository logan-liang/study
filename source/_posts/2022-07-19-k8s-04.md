---
title: Kubelet
tags:
  - k8s-核心组件
categories:
  - Kubernetes
comments: true
date: 2022-07-19 17:15:40
---


### Kubelet

每个Node节点上都运行一个Kubelet服务进程，默认监听1250端口，接收并执行Master发来的指令，管理Pod及Pod中的容器。每个Kubelet进程会在API Server上注册所在Node节点的信息，定期向Master节点汇报节点的资源使用情况，并通过cAdvisor监控节点和容器的资源。

### 节点管理

节点管理主要是节点自注册和节点状态更新：

* Kubelet可以通过设置启动参数`--register-node`来确定是否向API Server注册自己。
* 如果Kubelet没有选择自注册模式，则需要用户自己设置Node资源信息，同时需要告知Kubelet集群上的API Server的位置；
* Kubelet在启动时通过API Server注册节点信息，并定时向API Server发送节点新消息，API Server在接收到新消息后，将信息写入etcd。

### Pod管理

#### 获取Pod清单

向Kubelet提供节点上需要运行的Pod清单的方法：

* 文件：启动参数 --config指定的配置目录下的文件（默认 /etc/kubernetes/manifests）。该文件每20秒重新检查一次（可配置）。
* HTTP endpoint（URL）：启动参数 --manifest-url设置。每20秒检查一次这个端点（可配置）。
* API Server：通过API Server监听etcd目录，同步Pod清单。
* HTTP Server：kubelet侦听HTTP请求，并响应简单的API已提交新的Pod清单。

#### 通过API Server获取Pod清单及创建Pod的过程

Kubelet 通过 API Server Client(Kubelet 启动时创建)使用 Watch 加 List 的方式监听 "/registry/nodes/$ 当前节点名" 和 “/registry/pods” 目录，将获取的信息同步到本地缓存中。

Kubelet 监听 etcd，所有针对 Pod 的操作都将会被 Kubelet 监听到。如果发现有新的绑定到本节点的 Pod，则按照 Pod 清单的要求创建该 Pod。

如果发现本地的 Pod 被修改，则 Kubelet 会做出相应的修改，比如删除 Pod 中某个容器时，则通过 Docker Client 删除该容器。 如果发现删除本节点的 Pod，则删除相应的 Pod，并通过 Docker Client 删除 Pod 中的容器。

Kubelet 读取监听到的信息，如果是创建和修改 Pod 任务，则执行如下处理：

* 为该Pod创建一个数据目录；
* 从API Server读取该Pod清单；
* 为该Pod挂载外部卷；
* 下载Pod用到的Secret；
* 检查已经在节点上运行的Pod，如果该Pod没有容器或Pause容器没有启动，则先停止Pod里所有的容器的进程。如果在Pod中有需要删除的容器，则删除这些容器。
* 用"kubernetes/pause"镜像为每个Pod创建一个容器，Pause容器用于接管Pod中所有其他容器的网络。每创建一个新的Pod，Kubelet都会创建一个Pause容器，然后创建其他容器。
* 为Pod中的每个容器做如下处理：
    * 为容器计算一个hash值，然后用容器的名字去Dokcer查询对应容器的hash值。若查找到容器，且两者hash值不同，则停止Docker中容器的进程，并停止与之关联的Pause容器的进程；若两者相同，则不做任何处理。
    * 如果容器被终止了，且容器没有指定的resetPolicy，则不做任何处理。
    * 调用Docker Client下载容器镜像，调用Docker Client运行容器。

#### Static Pod

所有以非API Server方式创建的Pod都叫Static Pod。Kubelet将Static Pod的状态汇报给API Server，API Server为该Static Pod创建一个Mirror Pod和其相匹配。Mirror Pod的状态将真实反映Static Pod的状态。当Static Pod被删除时，与之相对应的Mirror Pod也会被删除。

### 容器健康检查

Pod通过两类探针检查容器的健康状态：

* LivenessProbe探针：用于判断容器是否健康，告诉Kubelet一个容器什么时候处于不健康的状态。如果LivenessProbe探针探测到容器不健康，则Kubelet将伤处该容器，并根据容器的重启策略做相应的处理。
如果一个容器不包含LivenessProbe探针，那么Kubelet认为该容器的LivenessProbe探针返回的值永远是"Success";
* ReadinessProbe：用于判断容器是否启动完成且准备接收请求。如果ReadinessProbe探针探测到失败，则Pod的状态将被修改。Endpoint Controller将从Service的Endpoint中删除包含该容器所在Pod的IP地址的Endpoint条目。

kubelet定期调用容器中的LivenessProbe探针来诊断容器的健康状况。LivenessProbe包含如下三种实现方式：

* ExecAction：在容器内部执行一个命令，如果该命令的退出状态码为0，则表明容器健康；
* TCPSocketAction：通过容器的IP地址和端口号及路径调用HTTP GET方法，如果响应的状态码大于等于200且小于等于400，则认为容器状态健康。

### Kubelet Eviction（驱逐）

Kubelet会监控资源的使用情况，并使用驱逐机制防止计算和存储资源耗尽。在驱逐时，Kubelet将Pod的所有容器停止，并将PodPhase设置为Failed。

Kubelet定期（housekeeping-interval）检查系统的资源是否达到了预先配置的驱逐阈值，包括：

```
    memory.available
    nodefs.available
    nodefs.inodesFree
    imagefs.available
    imagefs.inodesFree
```
这些驱逐阈值可以使用百分比，也可以使用绝对值

这些驱逐信号可以分为软驱逐和硬驱逐

* 软驱逐（soft Eviction）：配合驱逐宽限期一起使用。系统资源达到软驱逐阈值并在超过宽限期之后才会执行驱逐动作。
* 硬驱逐（Hard Eviction）：系统资源达到硬驱逐阈值时立即执行驱逐动作。

#### 驱逐动做包括获首届点资源和驱逐用户Pod两种：
* 回收节点资源
    * 配置了imagefs阈值时
        * 达到nodefs阈值：删除已停止的Pod
        * 达到imagefs阈值：删除未使用的镜像
    * 未配置imagefs阈值时
        * 达到nodefs阈值时，按照删除已停止的Pod和删除未使用镜像的顺序清理资源
* 驱逐用户Pod
    * 驱逐顺序为：BestEffort、Burstable、Guaranteed
    * 配置了imagefs阈值时
        * 达到nodefs阈值，基于nodefs用量驱逐
        * 达到imagefs阈值，基于imagefs用量驱逐
    * 未配置imagefs阈值时
        * 达到nodefs阈值时，按照总磁盘使用驱逐


### kubelet工作原理

如下kubelet内部组件结构图所示，kubelet由许多内部组件构成

* Kubelet API，包括10250端口的认证API、4194端口的cAdvisor API、10255端口的只读API以及10248端口的健康检查API
* syncLoop：从API或者manifest目录接收Pod更新，发送到podWorkers处理，大量使用channel处理异步请求
* 辅助的manager，如cAdvisor、PLEG、Volume Manager等，处理syncLoop以外的其他工作
* CRI：容器执行引擎接口，负责与container runtime shim通信
* 容器执行引擎，如dockershim、rkt等
* 网络插件，目前支持CNI和kubenet

