{"meta":{"title":"博客","subtitle":"","description":"","author":"Logan","url":"https://logan-liang.github.io/study","root":"/study/"},"pages":[{"title":"About","date":"2021-03-06T07:16:03.000Z","updated":"2022-07-05T01:23:33.926Z","comments":true,"path":"about/index.html","permalink":"https://logan-liang.github.io/study/about/index.html","excerpt":"","text":""},{"title":"Categories","date":"2021-03-06T07:14:09.000Z","updated":"2022-07-05T01:23:33.926Z","comments":true,"path":"categories/index.html","permalink":"https://logan-liang.github.io/study/categories/index.html","excerpt":"","text":""},{"title":"Repository","date":"2021-03-06T07:15:51.000Z","updated":"2022-07-05T01:23:33.926Z","comments":true,"path":"repository/index.html","permalink":"https://logan-liang.github.io/study/repository/index.html","excerpt":"","text":""},{"title":"Tags","date":"2021-03-06T07:15:40.000Z","updated":"2022-07-05T01:23:33.926Z","comments":true,"path":"tags/index.html","permalink":"https://logan-liang.github.io/study/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Namespace","slug":"k8s-14","date":"2022-07-19T09:16:35.000Z","updated":"2022-07-19T09:16:35.680Z","comments":true,"path":"2022/07/19/k8s-14/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/19/k8s-14/","excerpt":"","text":"Namespace是对一组资源和对象的抽象集合，比如可以用来将系统内部的对象划分为不同的项目组或用户组。常见的pod，service，replication controller和deployment等都是属于某一个namespace的，而node，persistent volume，namespace等资源则不属于任何namespace。 创建1234apiVersion: v1kind: Namespacemetadata: name: new-namespace 删除kubectl delete namespaces new-namespace","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://logan-liang.github.io/study/categories/Kubernetes/"}],"tags":[{"name":"k8s-资源对象","slug":"k8s-资源对象","permalink":"https://logan-liang.github.io/study/tags/k8s-%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1/"}]},{"title":"Job","slug":"k8s-13","date":"2022-07-19T09:16:29.000Z","updated":"2022-07-19T09:16:29.031Z","comments":true,"path":"2022/07/19/k8s-13/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/19/k8s-13/","excerpt":"","text":"JobJob负责批量处理短暂的一次性任务，即仅执行一次的任务，它保证批处理任务的一个或多个Pod成功结束。 Job类型 非并行Job：通常创建一个Pod直至其成功结束 固定结束次数的Job：设置 .spec.completions，创建多个Pod，直到.spec.completions个Pod成功结束 带有工作队列的并行Job：设置 .spec.Parallelism 但不设置 .spec.completions，当所有 Pod 结束并且至少一个成功时，Job 就认为是成功 123456789101112131415apiVersion: batch&#x2F;v1kind: Jobmetadata: name: busyboxspec: completions: 3 template: metadata: name: busybox spec: containers: - name: busybox image: busybox command: [&quot;echo&quot;, &quot;hello&quot;] restartPolicy: Never","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://logan-liang.github.io/study/categories/Kubernetes/"}],"tags":[{"name":"k8s-资源对象","slug":"k8s-资源对象","permalink":"https://logan-liang.github.io/study/tags/k8s-%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1/"}]},{"title":"Ingress","slug":"k8s-12","date":"2022-07-19T09:16:23.000Z","updated":"2022-07-19T09:16:23.377Z","comments":true,"path":"2022/07/19/k8s-12/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/19/k8s-12/","excerpt":"","text":"Ingress通常情况下，service和pod的IP仅可在集群内部访问。集群外部的请求需要通过负载均衡转发到service在Node上暴露的NodePort上，然后再由kube-proxy通过边缘路由器将其转给相关的Pod或者丢弃。 Ingress可以给Serivce提供集群外部访问的URL、负载均衡、SSL终止、HTTP路由等。为了配置这些Ingress规则，集群管理员需要部署一个Ingress Controller，它监听Ingress和service的变化，并根据规则配置负载均衡并提供访问入口。 Ingress类型单服务Ingress12345678apiVersion: extensions&#x2F;v1beta1kind: Ingressmetadata: name: test-ingressspec: backend: serviceName: testsvc servicePort: 80 多服务的Ingress1234567891011121314151617apiVersion: extensions&#x2F;v1beta1kind: Ingressmetadata: name: testspec: rules: - host: foo.bar.com http: paths: - path: &#x2F;foo backend: serviceName: s1 servicePort: 80 - path: &#x2F;bar backend: serviceName: s2 servicePort: 80 虚拟主机 Ingress12345678910111213rules:- host: foo.bar.com http: paths: - backend: serviceName: s1 servicePort: 80- host: bar.foo.com http: paths: - backend: serviceName: s2 servicePort: 80 TLS IngressTLS Ingress通过Secret获取TLS私钥和证书，来执行TLS终止。如果Ingress中的TLS配置部分指定了不同的主机，则它们将根据通过SNI TLS扩展指定的主机名在多个相同端口上进行复用。 1234567891011121314151617181920apiVersion: v1data: tls.crt: base64 encoded cert tls.key: base64 encoded keykind: Secretmetadata: name: testsecret namespace: defaulttype: OpaqueapiVersion: extensions&#x2F;v1beta1kind: Ingressmetadata: name: no-rules-mapspec: tls: - secretName: testsecret backend: serviceName: s1 servicePort: 80","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://logan-liang.github.io/study/categories/Kubernetes/"}],"tags":[{"name":"k8s-资源对象","slug":"k8s-资源对象","permalink":"https://logan-liang.github.io/study/tags/k8s-%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1/"}]},{"title":"Deployment","slug":"k8s-11","date":"2022-07-19T09:16:18.000Z","updated":"2022-07-19T09:16:18.976Z","comments":true,"path":"2022/07/19/k8s-11/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/19/k8s-11/","excerpt":"","text":"为Pod和ReplicaSet提供了一个声明式定义方法，用来替代以前的ReplicationController来方便的管理应用。 创建Deployment kubectl create -f docs/user-guide/nginx-deployment.yaml --record 将kubectl的 -record的flag设置为true可以在annotation中记录当前命令创建或者升级了该资源。 kubectl get pods --show-labels查看定义的标签，用于绑定svc 更新Deploymentkubectl set image deployment/nginx-deployment nginx=nginx:1.9.1 //设置deployment的imagekubectl edit deployment/nginx-deployment //编辑deployment 文件kubectl rollout status deployment/nginx-deployment //查看滚动更新状态kubectl get rs //查看副本情况 kubectl apply -f xxx.yaml //执行文件方式 回退Deploymentkubectl rollout history deployment/nginx-deployment //检查升级历史 kubectl rollout history deployment/nginx-deployment --revision=2 //查看单个 revision的详细信息 kubectl rollout undo deployment/nginx-deployment --to-revision=2 //使用 –to-revision 参数指定某个历史版本 你也可以通过设置.spec.revisonHistoryLimit项来指定deployment最多保留多少revison历史记录。默认会保留所有，如果设置为0，就不允许回退了。 Deployment 扩容kubectl scale deployment nginx-deployment --replicas 10kubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://logan-liang.github.io/study/categories/Kubernetes/"}],"tags":[{"name":"k8s-资源对象","slug":"k8s-资源对象","permalink":"https://logan-liang.github.io/study/tags/k8s-%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1/"}]},{"title":"DaemonSet","slug":"k8s-10","date":"2022-07-19T09:16:14.000Z","updated":"2022-07-19T09:16:14.408Z","comments":true,"path":"2022/07/19/k8s-10/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/19/k8s-10/","excerpt":"","text":"DaemonSetDaemonSet 保证在每个Node上都运行一个容器副本，常用来部署一些集群的日志、监控或者其它系统管理应用。应用包括： 日志收集 系统监控 系统程序 滚动更新支持DaemonSet的滚动更新，可以通过.spec.updateStrategy.type设置更新策略。目前只支持两种： OnDelete:默认策略，更新模板后，只有手动删除了旧的Pod后才会创建新的Pod RollingUpdate:更新DaemonSet模板后，自动删除旧的Pod并创建新的Pod 在使用RollingUpdate策略时，还可以设置 .spec.updateStrategy.rollingUpdate.maxUnavailable，默认 1 spec.minReadySeconds,默认 0 回滚12345678910# 查询历史版本$ kubectl rollout history daemonset &lt;daemonset-name&gt;# 查询某个历史版本的详细信息$ kubectl rollout history daemonset &lt;daemonset-name&gt; --revision&#x3D;1# 回滚$ kubectl rollout undo daemonset &lt;daemonset-name&gt; --to-revision&#x3D;&lt;revision&gt;# 查询回滚状态$ kubectl rollout status ds&#x2F;&lt;daemonset-name&gt; 指定Node节点DaemonSet会忽略Node的unschedulable状态，有两种方式来指定Pod只运行在指定的Node节点上： nodeSelector:只调度到匹配指定label的Node上 nodeAffinity：功能更丰富的Node选择器，比如支持集合操作 podAffinity：调度到满足条件的Pod所在的Node上","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://logan-liang.github.io/study/categories/Kubernetes/"}],"tags":[{"name":"k8s-资源对象","slug":"k8s-资源对象","permalink":"https://logan-liang.github.io/study/tags/k8s-%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1/"}]},{"title":"CronJob","slug":"k8s-09","date":"2022-07-19T09:16:09.000Z","updated":"2022-07-19T09:16:09.896Z","comments":true,"path":"2022/07/19/k8s-09/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/19/k8s-09/","excerpt":"","text":"CronJob即定时任务，就类似于Linux系统的Crontab，在指定时间周期运行指定的任务。 CronJob Spec .spec.schedule指定任务运行周期，格式同Cron .spec.jobTemplate 指定需要运行的任务，格式同Job .spec.startingDeadlineSends 指定任务开始的截止期限 .spec.concurrencyPolicy 指定任务的并发策略，支持Allow、Forbid、Replace三个选项 123456789101112131415161718apiVersion: batch&#x2F;v1beta1kind: CronJobmetadata: name: hellospec: schedule: &quot;*&#x2F;1 * * * *&quot; jobTemplate: spec: template: spec: containers: - name: hello image: busybox args: - &#x2F;bin&#x2F;sh - -c - date; echo Hello from the Kubernetes cluster restartPolicy: OnFailure","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://logan-liang.github.io/study/categories/Kubernetes/"}],"tags":[{"name":"k8s-资源对象","slug":"k8s-资源对象","permalink":"https://logan-liang.github.io/study/tags/k8s-%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1/"}]},{"title":"ConfigMap","slug":"k8s-08","date":"2022-07-19T09:16:05.000Z","updated":"2022-07-19T09:16:05.958Z","comments":true,"path":"2022/07/19/k8s-08/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/19/k8s-08/","excerpt":"","text":"IntroduceConfigMap组件可以很好的帮助我们实现应用和配置分离，避免因为修改配置项而重新构建镜像。 ConfigMap用于保存配置数据的键值对，可以用来保存单个属性，也可以用来保存配置文件。 ConfigMap Creation可以使用 kubectl create configmap从文件、目录或key-value字符串创建ConfigMap。也可以通过kubectl create -f file创建。 从key-value字符串创建kubectl create configmap special-config --from-literal=special.how=very 从env文件创建kubectl create configmap special-config --from-env-file=config.env 从目录创建kubectl create configmap special-config --from-file=config/ 从 yaml/json文件创建kubectl create -f conf.yaml ConfigMap使用可以通过三种方式在Pod中使用，分别为：设置环境变量、设置容器命令行参数以及在Volume中直接挂在文件或目录。 用作环境变量123456789101112131415spec: env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type envFrom: - configMapRef: name: env-config 用作命令行参数将 ConfigMap 用作命令行参数时，需要先把 ConfigMap 的数据保存在环境变量中，然后通过 $(VAR_NAME) 的方式引用环境变量. 1234567891011env: - name: SPECIAL_LEVEL_KEY valueFrom: configMapKeyRef: name: special-config key: special.how - name: SPECIAL_TYPE_KEY valueFrom: configMapKeyRef: name: special-config key: special.type 使用volume将ConfigMap作为文件或目录直接挂载将创建的 ConfigMap 直接挂载至 Pod 的 / etc/config 目录下，其中每一个 key-value 键值对都会生成一个文件，key 为文件名，value 为内容 使用 subpath 将 ConfigMap 作为单独的文件挂载到目录在一般情况下 configmap 挂载文件时，会先覆盖掉挂载目录，然后再将 congfigmap 中的内容作为文件挂载进行。如果想不对原来的文件夹下的文件造成覆盖，只是将 configmap 中的每个 key，按照文件的方式挂载到目录下，可以使用 subpath 参数。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://logan-liang.github.io/study/categories/Kubernetes/"}],"tags":[{"name":"k8s-资源对象","slug":"k8s-资源对象","permalink":"https://logan-liang.github.io/study/tags/k8s-%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1/"}]},{"title":"kube-dns","slug":"k8s-07","date":"2022-07-19T09:16:01.000Z","updated":"2022-07-19T09:16:01.913Z","comments":true,"path":"2022/07/19/k8s-07/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/19/k8s-07/","excerpt":"","text":"Horizontal Pod Autoscaling(HPA)HPA可以根据CPU使用率或应用自定义metrics自动扩展Pod数量。 控制管理器每隔30s查询metrics的资源使用情况 支持三种metrics类型 预定义metrics以利用率的方式计算 自定义的Pod metrics，以原始值的方式计算 自定义的object metrics 支持两种metrics查询方式：Heapster和自定义的REST API 支持多 metrics 自定义metrics使用方法 控制管理器开启 horizontal-pod-autoscaler-use-reset-clients 控制观其配置的 --master或者 --kubeconfig 在API Server Aggregator中注册自定义的metrics API 比如 HorizontalPodAutoscaler 保证每个 Pod 占用 50% CPU、1000pps 以及 10000 请求 / s： 12345678910111213141516171819202122232425262728293031323334353637383940apiVersion: autoscaling&#x2F;v1kind: HorizontalPodAutoscalermetadata: name: php-apache namespace: defaultspec: scaleTargetRef: apiVersion: apps&#x2F;v1beta1 kind: Deployment name: php-apache minReplicas: 1 maxReplicas: 10 metrics: - type: Resource resource: name: cpu targetAverageUtilization: 50 - type: Pods pods: metricName: packets-per-second targetAverageValue: 1k - type: Object object: metricName: requests-per-second target: apiVersion: extensions&#x2F;v1beta1 kind: Ingress name: main-route targetValue: 10kstatus: observedGeneration: 1 lastScaleTime: &lt;some-time&gt; currentReplicas: 1 desiredReplicas: 1 currentMetrics: - type: Resource resource: name: cpu currentAverageUtilization: 0 currentAverageValue: 0 状态条件可以在客户端中看到Kubernete为HorizontalPodAutoscaler 设置的状态条件status.conditions，用来判断HorizontalPodAutoscaler 是否可以扩展、是否开启扩展意识是否收到限制。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://logan-liang.github.io/study/categories/Kubernetes/"}],"tags":[{"name":"k8s-资源对象","slug":"k8s-资源对象","permalink":"https://logan-liang.github.io/study/tags/k8s-%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1/"}]},{"title":"kube-dns","slug":"k8s-06","date":"2022-07-19T09:15:57.000Z","updated":"2022-07-19T09:15:57.403Z","comments":true,"path":"2022/07/19/k8s-06/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/19/k8s-06/","excerpt":"","text":"DNSDNS是Kubernetes的核心功能之一，通过kube-dns或CoreDNS作为集群的必备扩展来提供命名服务。 CoreDNS从v1.11开始可以使用CoreDNS来提供命名服务，并从v1.13开始称为默认DNS服务。CoreDNS的特点是效率更高，资源占用率更小，推荐使用CoreDNS替代kube-dns为集群提供DNS服务。 支持的DNS格式 Service A record：生成my-svc.my-namespace.svc.cluster.local，解析IP分为两种情况 普通Service解析为Cluster IP Headless Service 解析为指定的Pod IP列表 SRV record：生成_my-port-name._my-port-protocol.my-svc.my-namespace.svc.cluster.local Pod A record：pod-ip-address.my-namespace.pod.cluster.local 指定hostname和subdomain：hostname.custom-subdomain.default.svc.cluster.local，如下所示 123456789101112131415apiVersion: v1kind: Podmetadata: name: busybox2 labels: name: busyboxspec: hostname: busybox-2 subdomain: default-subdomain containers: - image: busybox command: - sleep - &quot;3600&quot; name: busybox 支持配置私有DNS服务器和上游DNS服务器从V1.6开始，可以通过为kube-dns提供ConfigMap来实现对存根域以及上游名称服务器的自定义指定。例如： 1234567891011插入了一个单独的私有根 DNS 服务器和两个上游 DNS 服务器apiVersion: v1kind: ConfigMapmetadata: name: kube-dns namespace: kube-systemdata: stubDomains: | &#123;“acme.local”: [“1.2.3.4”]&#125; upstreamNameservers: | [“8.8.8.8”, “8.8.4.4”] 使用上述特定配置，查询请求首先会被发送到kube-dns的DNS缓存层（Dnsmasq）。Dnsmasq服务器会先检查请求的后缀，带有集群后缀（例如：.cluster.local）的请求会被发往kube-dns，拥有存根域后缀的名称（例如：.acme.local）将会被发送到配置的私有DNS服务器[1.2.3.4].最后，不满足任何这些后缀的请求将会被发送到上游DNS [8.8.8.8, 8.8.4.4]。 kube-dns工作原理kube-dns由三个容器构成： kube-dns：DNS服务的核心组件，主要由KubeDNS和SkyDNS组成 KubeDNS负责监听Service和EndPoint的变化情况，并将相关的信息更新到SkyDNS中 SkyDNS负责DNS解析，监听在10053端口（tcp/udp）,同时也监听在10055端口提供metrics kube-dns还监听了8081端口，以供健康检查使用 dnsmasq-nanny：负责启动dnsmasq，并在配置发生变化时重启dnsmasq dnsmasq的upstram为SkyDNS，即集群内部的DNS解析由SkyDNS负责 sidecar：负责健康检查和DNS metrics（监听在10054端口）","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://logan-liang.github.io/study/categories/Kubernetes/"}],"tags":[{"name":"k8s-核心组件","slug":"k8s-核心组件","permalink":"https://logan-liang.github.io/study/tags/k8s-%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"}]},{"title":"kube-proxy","slug":"k8s-05","date":"2022-07-19T09:15:48.000Z","updated":"2022-07-19T09:15:48.711Z","comments":true,"path":"2022/07/19/k8s-05/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/19/k8s-05/","excerpt":"","text":"kube-proxy每台机器上都运行一个kube-proxy服务，它监听API Server中service和endpoint的变化情况，并通过iptables等来为服务配置负载均衡。 kube-proxy可以直接运行在物理机上，也可以以static pod 或daemonset的方式运行。 kube-proxy当前支持以下几种实现 userspace：最早的负载均衡方案，它在用户空间监听一个端口，所有服务通过iptables转发到这个端口，然后再其内部负载均衡到实际的Pod。该方式最主要的问题是效率低，有明显的性能瓶颈。 iptables：目前推荐的方案，完全以iptables规则的方式来实现service负载均衡。该方式最主要的问题是在服务多的时候产生太多的iptables规则，非增量式更新会引入一定的延时，大规模情况下有明显的性能问题 ipvs：为解决iptables模式的性能问题，v1.11新增了ipvs模式，采用增量式更新，并可以保证service更新期间连接保持不断开 kube-proxy工作原理kube-proxy监听API Server中server和endpoint的变化情况，并通过userspace、iptables、ipvs或winuserspace等proxier来为服务配置负载均衡。 kube-proxy不足kube-proxy目前仅支持TCP和UDP，不支持HTTP路由，并且也没有健康检查机制。这些可以通过自定义Ingress Controller的方法来解决。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://logan-liang.github.io/study/categories/Kubernetes/"}],"tags":[{"name":"k8s-核心组件","slug":"k8s-核心组件","permalink":"https://logan-liang.github.io/study/tags/k8s-%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"}]},{"title":"Kubelet","slug":"k8s-04","date":"2022-07-19T09:15:40.000Z","updated":"2022-07-19T09:15:40.206Z","comments":true,"path":"2022/07/19/k8s-04/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/19/k8s-04/","excerpt":"","text":"Kubelet每个Node节点上都运行一个Kubelet服务进程，默认监听1250端口，接收并执行Master发来的指令，管理Pod及Pod中的容器。每个Kubelet进程会在API Server上注册所在Node节点的信息，定期向Master节点汇报节点的资源使用情况，并通过cAdvisor监控节点和容器的资源。 节点管理节点管理主要是节点自注册和节点状态更新： Kubelet可以通过设置启动参数--register-node来确定是否向API Server注册自己。 如果Kubelet没有选择自注册模式，则需要用户自己设置Node资源信息，同时需要告知Kubelet集群上的API Server的位置； Kubelet在启动时通过API Server注册节点信息，并定时向API Server发送节点新消息，API Server在接收到新消息后，将信息写入etcd。 Pod管理获取Pod清单向Kubelet提供节点上需要运行的Pod清单的方法： 文件：启动参数 –config指定的配置目录下的文件（默认 /etc/kubernetes/manifests）。该文件每20秒重新检查一次（可配置）。 HTTP endpoint（URL）：启动参数 –manifest-url设置。每20秒检查一次这个端点（可配置）。 API Server：通过API Server监听etcd目录，同步Pod清单。 HTTP Server：kubelet侦听HTTP请求，并响应简单的API已提交新的Pod清单。 通过API Server获取Pod清单及创建Pod的过程Kubelet 通过 API Server Client(Kubelet 启动时创建)使用 Watch 加 List 的方式监听 “/registry/nodes/$ 当前节点名” 和 “/registry/pods” 目录，将获取的信息同步到本地缓存中。 Kubelet 监听 etcd，所有针对 Pod 的操作都将会被 Kubelet 监听到。如果发现有新的绑定到本节点的 Pod，则按照 Pod 清单的要求创建该 Pod。 如果发现本地的 Pod 被修改，则 Kubelet 会做出相应的修改，比如删除 Pod 中某个容器时，则通过 Docker Client 删除该容器。 如果发现删除本节点的 Pod，则删除相应的 Pod，并通过 Docker Client 删除 Pod 中的容器。 Kubelet 读取监听到的信息，如果是创建和修改 Pod 任务，则执行如下处理： 为该Pod创建一个数据目录； 从API Server读取该Pod清单； 为该Pod挂载外部卷； 下载Pod用到的Secret； 检查已经在节点上运行的Pod，如果该Pod没有容器或Pause容器没有启动，则先停止Pod里所有的容器的进程。如果在Pod中有需要删除的容器，则删除这些容器。 用”kubernetes/pause”镜像为每个Pod创建一个容器，Pause容器用于接管Pod中所有其他容器的网络。每创建一个新的Pod，Kubelet都会创建一个Pause容器，然后创建其他容器。 为Pod中的每个容器做如下处理： 为容器计算一个hash值，然后用容器的名字去Dokcer查询对应容器的hash值。若查找到容器，且两者hash值不同，则停止Docker中容器的进程，并停止与之关联的Pause容器的进程；若两者相同，则不做任何处理。 如果容器被终止了，且容器没有指定的resetPolicy，则不做任何处理。 调用Docker Client下载容器镜像，调用Docker Client运行容器。 Static Pod所有以非API Server方式创建的Pod都叫Static Pod。Kubelet将Static Pod的状态汇报给API Server，API Server为该Static Pod创建一个Mirror Pod和其相匹配。Mirror Pod的状态将真实反映Static Pod的状态。当Static Pod被删除时，与之相对应的Mirror Pod也会被删除。 容器健康检查Pod通过两类探针检查容器的健康状态： LivenessProbe探针：用于判断容器是否健康，告诉Kubelet一个容器什么时候处于不健康的状态。如果LivenessProbe探针探测到容器不健康，则Kubelet将伤处该容器，并根据容器的重启策略做相应的处理。如果一个容器不包含LivenessProbe探针，那么Kubelet认为该容器的LivenessProbe探针返回的值永远是”Success”; ReadinessProbe：用于判断容器是否启动完成且准备接收请求。如果ReadinessProbe探针探测到失败，则Pod的状态将被修改。Endpoint Controller将从Service的Endpoint中删除包含该容器所在Pod的IP地址的Endpoint条目。 kubelet定期调用容器中的LivenessProbe探针来诊断容器的健康状况。LivenessProbe包含如下三种实现方式： ExecAction：在容器内部执行一个命令，如果该命令的退出状态码为0，则表明容器健康； TCPSocketAction：通过容器的IP地址和端口号及路径调用HTTP GET方法，如果响应的状态码大于等于200且小于等于400，则认为容器状态健康。 Kubelet Eviction（驱逐）Kubelet会监控资源的使用情况，并使用驱逐机制防止计算和存储资源耗尽。在驱逐时，Kubelet将Pod的所有容器停止，并将PodPhase设置为Failed。 Kubelet定期（housekeeping-interval）检查系统的资源是否达到了预先配置的驱逐阈值，包括： 12345memory.availablenodefs.availablenodefs.inodesFreeimagefs.availableimagefs.inodesFree 这些驱逐阈值可以使用百分比，也可以使用绝对值 这些驱逐信号可以分为软驱逐和硬驱逐 软驱逐（soft Eviction）：配合驱逐宽限期一起使用。系统资源达到软驱逐阈值并在超过宽限期之后才会执行驱逐动作。 硬驱逐（Hard Eviction）：系统资源达到硬驱逐阈值时立即执行驱逐动作。 驱逐动做包括获首届点资源和驱逐用户Pod两种： 回收节点资源 配置了imagefs阈值时 达到nodefs阈值：删除已停止的Pod 达到imagefs阈值：删除未使用的镜像 未配置imagefs阈值时 达到nodefs阈值时，按照删除已停止的Pod和删除未使用镜像的顺序清理资源 驱逐用户Pod 驱逐顺序为：BestEffort、Burstable、Guaranteed 配置了imagefs阈值时 达到nodefs阈值，基于nodefs用量驱逐 达到imagefs阈值，基于imagefs用量驱逐 未配置imagefs阈值时 达到nodefs阈值时，按照总磁盘使用驱逐 kubelet工作原理如下kubelet内部组件结构图所示，kubelet由许多内部组件构成 Kubelet API，包括10250端口的认证API、4194端口的cAdvisor API、10255端口的只读API以及10248端口的健康检查API syncLoop：从API或者manifest目录接收Pod更新，发送到podWorkers处理，大量使用channel处理异步请求 辅助的manager，如cAdvisor、PLEG、Volume Manager等，处理syncLoop以外的其他工作 CRI：容器执行引擎接口，负责与container runtime shim通信 容器执行引擎，如dockershim、rkt等 网络插件，目前支持CNI和kubenet","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://logan-liang.github.io/study/categories/Kubernetes/"}],"tags":[{"name":"k8s-核心组件","slug":"k8s-核心组件","permalink":"https://logan-liang.github.io/study/tags/k8s-%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"}]},{"title":"Controller Manager","slug":"k8s-03","date":"2022-07-19T09:15:32.000Z","updated":"2022-07-19T09:15:32.278Z","comments":true,"path":"2022/07/19/k8s-03/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/19/k8s-03/","excerpt":"","text":"Controller ManagerController Manager 由 kube-controller-manager和cloud-controller-manager组成，是Kubernetes的大脑，它通过apiserver监控整个集群的状态，并确保集群处于预期的工作状态。 kube-controller-manager由一系列的控制器组成 Replication Controller Node Controller CronJob Controller Daemon Controller Deployment Controller Endpoint Controller Garbage Collector Namespace Controller Job Controller Pod AutoScaler RelicaSet Service Controller ServiceAccount Controller StatefulSet Controller Volume Controller Resource quota Controller cloud-controller-manager 在Kubernete启用Cloud Provider的时候才需要，用来配合云服务提供商的控制，也包括一系列的控制器，如 Node Controller Route Controller Service Controller 高可用在启动时设置 --leader-elect=true后，controller manager会使用多节点选主的方式选择主节点。只有主节点才会调用StartControllers()启动所有控制器，而其他从节点则仅执行选主算法。 多节点选主的实现方法见leaderelection.go。 高性能从1.7开始，所有需要监控资源变化情况的调用均推荐使用Infomer。Infomer提供了基于事件通知的只读缓存机制，可以注册资源变化的回调函数，并可以极大减少API的调用。 Node EvictionNode控制器在节点异常后，会按照默认的效率（--node-eviction-rate=0.1,即每10秒一个节点的速率）进行Node的驱逐。Node控制器按照Zone将节点划分为不同的组，再跟进Zone的状态进行速率调整： Normal：所有节点都Ready，默认速率驱逐。 PartialDisruption：即超过33%的节点NotReady的状态。当异常节点比例大于unhealthy-zone-threshold=0.5时开始减慢速率。 小集群（即节点数量小于 –large-cluster-size-threshold=50）：停止驱逐 大集群，减慢速率为 –secondary-node-eviction-rate=0.01 FullDisruption：所有节点都 NotReady，返回使用默认速率驱逐。但当所有 Zone 都处在 FullDisruption 时，停止驱逐。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://logan-liang.github.io/study/categories/Kubernetes/"}],"tags":[{"name":"k8s-核心组件","slug":"k8s-核心组件","permalink":"https://logan-liang.github.io/study/tags/k8s-%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"}]},{"title":"kube-scheduler","slug":"k8s-02","date":"2022-07-19T09:15:26.000Z","updated":"2022-07-19T09:15:26.470Z","comments":true,"path":"2022/07/19/k8s-02/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/19/k8s-02/","excerpt":"","text":"kube-scheduler负责分配调度Pod到集群内的节点上，它监听kube-apiserver，查询还未分配Node的Pod，然后根据调度策略为这些Pod分配节点。 指定Node节点调度有三种方式指定Pod只运行在指定的Node节点上： nodeSelector: 只调度到匹配指定label的Node上。 nodeAffinity：功能更丰富的Node选择器，比如支持集合操作 podAffinity：调度到满足条件的Pod所在的Node上 nodeSelector示例首先给Node打上标签 kubectl label nodes node-01 disktype=ssd 然后在daemonset中指定nodeSelector 为 disktype=ssd： spec:nodeSelector:disktype:ssd nodeAffinity 示例nodeAffinity目前支持两种：requiredDuringSchedulingIgnoredDuringExecution 和 preferredDuringSchedulingIgnoredDuringExecution，分别代表必须满足条件和优选条件。比如下面的例子代表调度到包含标签 kubernetes.io/e2e-az-name 并且值为 e2e-az1 或 e2e-az2 的 Node 上，并且优选还带有标签 another-node-label-key=another-node-label-value 的 Node 1234567891011121314151617181920212223242526apiVersion: v1kind: Podmetadata: name: with-node-affinityspec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io&#x2F;e2e-az-name operator: In values: - e2e-az1 - e2e-az2 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: another-node-label-key operator: In values: - another-node-label-value containers: - name: with-node-affinity image: gcr.io&#x2F;google_containers&#x2F;pause:2.0 podAffinity示例podAffinity 基于 Pod 的标签来选择 Node，仅调度到满足条件 Pod 所在的 Node 上，支持 podAffinity 和 podAntiAffinity。这个功能比较绕，以下面的例子为例： 如果一个 “Node 所在 Zone 中包含至少一个带有 security=S1 标签且运行中的 Pod”，那么可以调度到该 Node 不调度到 “包含至少一个带有 security=S2 标签且运行中 Pod” 的 Node 上 Taints和tolerationsTaints和tolerations用于保证Pod不被调度到不合适的Node上，其中Taint应用于Node上，而toleration则应用于Pod上。 taint类型包括： NoSchedule：新的Pod不调度到该Node上，不影响正在运行的Pod PreferNoSchedule：soft版的NoSchedule，尽量不调度到该Node上 NoExecute：新的Pod不调度到该Node上，并且删除已在运行的Pod。Pod可以增加一个时间。 然而，当Pod的Tolerations匹配Node的所有Taints的时候可以调度到该Node上；当Pod是已经运行的时候，也不会被删除。另外对于NoExecute，如果Pod增加了一个tolerationSeconds，则会在该时间之后才删除Pod。 123456789101112131415正在运行且带有tolerationSeconds的Pod则会在600s之后删除。tolerations:- key: &quot;key1&quot; operator: &quot;Equal&quot; value: &quot;value1&quot; effect: &quot;NoSchedule&quot;- key: &quot;key1&quot; operator: &quot;Equal&quot; value: &quot;value1&quot; effect: &quot;NoExecute&quot; tolerationSeconds: 600- key: &quot;key2&quot; operator: &quot;Equal&quot; value: &quot;value2&quot; effect: &quot;NoSchedule&quot; 注意，DaemonSet创建的Pod会自动加上对node.alpha.kubernetes.io/unreachable 和 node.alpha.kubernetes.io/notReady 的 NoExecute Toleration，以避免它们因此被删除 优先级调度从v1.8开始，kube-scheduler支持定义Pod的优先级，从而保证高优先级的Pod优先调度。并从v1.11开始默认开启。 在指定Pod的优先级之前需要先定义一个PriorityClass，如： 1234567apiVersion: v1kind: PriorityClassmetadata: name: high-priorityvalue: 1000000globalDefault: falsedescription: &quot;This priority class should be used for XYZ service pods only.&quot; 其中： value为32位整数的优先级，该值越大，优先级越高 globalDefault用于未配置 PriorityClassName 的Pod，整个集群中应该只有一个PriorityClass将其设置为true 然后，在PodSpec中通过PriorityClassName 设置Pod的优先级： 123456789101112apiVersion: v1kind: Podmetadata: name: nginx labels: env: testspec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent priorityClassName: high-priority 多调度器如果默认的调度器不满足要求，还可以部署自定义的调度器。并且，在整个集群中还可以同时运行多个调度器实例，通过podSpec.schedulerName 来选择使用哪一个调度器。 12345....spec: # 选择使用自定义调度器 my-scheduler schedulerName: my-scheduler.... 调度器扩展kube-sceduler还支持使用--policy-config-file指定一个调度策略文件来自定义调度策略，比如 12345678910111213141516171819202122232425262728&#123;&quot;kind&quot; : &quot;Policy&quot;,&quot;apiVersion&quot; : &quot;v1&quot;,&quot;predicates&quot; : [ &#123;&quot;name&quot; : &quot;PodFitsHostPorts&quot;&#125;, &#123;&quot;name&quot; : &quot;PodFitsResources&quot;&#125;, &#123;&quot;name&quot; : &quot;NoDiskConflict&quot;&#125;, &#123;&quot;name&quot; : &quot;MatchNodeSelector&quot;&#125;, &#123;&quot;name&quot; : &quot;HostName&quot;&#125; ],&quot;priorities&quot; : [ &#123;&quot;name&quot; : &quot;LeastRequestedPriority&quot;, &quot;weight&quot; : 1&#125;, &#123;&quot;name&quot; : &quot;BalancedResourceAllocation&quot;, &quot;weight&quot; : 1&#125;, &#123;&quot;name&quot; : &quot;ServiceSpreadingPriority&quot;, &quot;weight&quot; : 1&#125;, &#123;&quot;name&quot; : &quot;EqualPriority&quot;, &quot;weight&quot; : 1&#125; ],&quot;extenders&quot;:[ &#123; &quot;urlPrefix&quot;: &quot;http:&#x2F;&#x2F;127.0.0.1:12346&#x2F;scheduler&quot;, &quot;apiVersion&quot;: &quot;v1beta1&quot;, &quot;filterVerb&quot;: &quot;filter&quot;, &quot;prioritizeVerb&quot;: &quot;prioritize&quot;, &quot;weight&quot;: 5, &quot;enableHttps&quot;: false, &quot;nodeCacheCapable&quot;: false &#125; ]&#125; kube-scheduler 调度分为两个阶段，predicate 和 priority predicate：过滤不符合条件的节点 priority：优先级排序，选择优先级最高的节点 predicates 策略 PodFitsPorts：同 PodFitsHostPorts PodFitsHostPorts：检查是否有 Host Ports 冲突 PodFitsResources：检查 Node 的资源是否充足，包括允许的 Pod 数量、CPU、内存、GPU 个数以及其他的 OpaqueIntResources HostName：检查 pod.Spec.NodeName 是否与候选节点一致 MatchNodeSelector：检查候选节点的 pod.Spec.NodeSelector 是否匹配 NoVolumeZoneConflict：检查 volume zone 是否冲突 MaxEBSVolumeCount：检查 AWS EBS Volume 数量是否过多（默认不超过 39） MaxGCEPDVolumeCount：检查 GCE PD Volume 数量是否过多（默认不超过 16） MaxAzureDiskVolumeCount：检查 Azure Disk Volume 数量是否过多（默认不超过 16） MatchInterPodAffinity：检查是否匹配 Pod 的亲和性要求 NoDiskConflict：检查是否存在 Volume 冲突，仅限于 GCE PD、AWS EBS、Ceph RBD 以及 ISCSI GeneralPredicates：分为 noncriticalPredicates 和 EssentialPredicates。noncriticalPredicates 中包含 PodFitsResources，EssentialPredicates 中包含 PodFitsHost，PodFitsHostPorts 和 PodSelectorMatches。 PodToleratesNodeTaints：检查 Pod 是否容忍 Node Taints CheckNodeMemoryPressure：检查 Pod 是否可以调度到 MemoryPressure 的节点上 CheckNodeDiskPressure：检查 Pod 是否可以调度到 DiskPressure 的节点上 NoVolumeNodeConflict：检查节点是否满足 Pod 所引用的 Volume 的条件 priorities 策略 SelectorSpreadPriority：优先减少节点上属于同一个 Service 或 Replication Controller 的 Pod 数量 InterPodAffinityPriority：优先将 Pod 调度到相同的拓扑上（如同一个节点、Rack、Zone 等） LeastRequestedPriority：优先调度到请求资源少的节点上 BalancedResourceAllocation：优先平衡各节点的资源使用 NodePreferAvoidPodsPriority：alpha.kubernetes.io/preferAvoidPods 字段判断, 权重为 10000，避免其他优先级策略的影响 NodeAffinityPriority：优先调度到匹配 NodeAffinity 的节点上 TaintTolerationPriority：优先调度到匹配 TaintToleration 的节点上 ServiceSpreadingPriority：尽量将同一个 service 的 Pod 分布到不同节点上，已经被 SelectorSpreadPriority 替代 [默认未使用] EqualPriority：将所有节点的优先级设置为 1[默认未使用] ImageLocalityPriority：尽量将使用大镜像的容器调度到已经下拉了该镜像的节点上 [默认未使用] MostRequestedPriority：尽量调度到已经使用过的 Node 上，特别适用于 cluster-autoscaler[默认未使用]","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://logan-liang.github.io/study/categories/Kubernetes/"}],"tags":[{"name":"k8s-核心组件","slug":"k8s-核心组件","permalink":"https://logan-liang.github.io/study/tags/k8s-%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"}]},{"title":"kube-apiserver","slug":"k8s-01","date":"2022-07-19T09:15:17.000Z","updated":"2022-07-19T09:15:17.779Z","comments":true,"path":"2022/07/19/k8s-01/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/19/k8s-01/","excerpt":"","text":"介绍是k8s最重要的核心组件之一，主要提供以下功能： 提供集群管理的REST API接口，包括认证授权、数据校验以及集群状态变更等 提供其他模块之间的数据交互和通信的枢纽 REST APIapi server支持同时提供https和http API，其中http API是非安全接口，不做任何认证授权机制，不建议生产环境启用。 在实际使用中，通常通过kubectl来访问apiserver，也可以通过k8s各个语言的client库来访问。 访问控制Kubernetes API的每个请求都会经过多阶段的访问控制之后才会被接受，这包括认证、授权以及准入控制等。 认证开启TLS时，所有的请求都需要首先认证。K8s支持多种认证机制，并支持同时开启多个认证插件。认证成功，则用户的username会传入授权模块做进一步授权验证；而对于认证失败的请求则返回401。 更多认证模块的使用方法可以参考 Kubernetes 认证插件。 授权认证之后的请求就到了授权模块。跟认证类似，k8s支持多种授权机制，并支持同时开启多个授权插件。成功则进一步请求验证；对于失败的请求则返回HTTP 403。 更多授权模块的使用方法可以参考 Kubernetes 授权插件。 准入控制准入控制用来对请求做进一步的验证或添加默认参数。不同于授权和认证只关心请求的用户和操作，准入控制还处理请求的内容，并且仅对创建、更新、删除或连接等有效，而对读操作无效。准入控制也支持同时开启多个插件，只有全部插件都通过的请求才可以放进系统。更多准入控制模块的使用方法可以参考 Kubernetes 准入控制。","categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://logan-liang.github.io/study/categories/Kubernetes/"}],"tags":[{"name":"k8s-核心组件","slug":"k8s-核心组件","permalink":"https://logan-liang.github.io/study/tags/k8s-%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"}]},{"title":"RabbitMQ-防数据丢失","slug":"RabbitMQ-03","date":"2022-07-06T09:54:21.000Z","updated":"2022-07-06T09:54:21.431Z","comments":true,"path":"2022/07/06/RabbitMQ-03/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/06/RabbitMQ-03/","excerpt":"","text":"数据丢失场景一条消息整个过程要经历两次的网络传输：从生产者发送到RabbitMQ服务器，从RabbitMQ服务器发送到消费者。 存储在队列中，如果没有队列没有对消息持久化，RabbitMQ服务器宕机重启会丢失数据。 生产者发送消息到RabbitMQ服务器过程中，RabbitMQ服务器如果宕机停止服务，消息会丢失。 消费者从RabbitMQ服务器获取队列中存储的数据消费，但是消费者程序出错或者宕机而没有正确消费，导致数据丢失。 解决方式消息持久化需要设置Exchange和Queue为持久化。具体设置查看工具包。 消息确认机制-confim生产者设置channel为confirm模式。 一旦信道进入confirm模式，所有在该信道上面发布的消息都会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后，broker就会发送一个确认给生产者（包含消息的唯一ID），这就使得生产者直到消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会将消息写入磁盘之后发出，broker回传给生产者的确认消息中deliver-tag域包含了确认消息的序列号，此外broker也可以设置basic.ack的multiple域，表示到这个序列号之前的所有消息都已经得到了处理。 confirm模式最大的好处在于它是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条信息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果MQ因为自身内部错误导致消息丢失，就会发送一条nack消息，生产者应用程序同样可以在回调方法中处理该nack消息。 编程模式 普通模式：每发送一条消息后，调用waitForConfirms()方法，等待服务器端confirm。实际上是一种串行confirm。 批量confirm模式：每发送一批消息后，调用waitForConfirms()方法，等待服务器端confirm。 异步confirm模式：提供一个回调方法，服务端confirm了一条或者多条消息后Client端会回调这个方法。 基于异步confirm模式的实现思路主要解决问题：在生产者发送到rabbit server时，因网络问题导致投递失败，从而数据丢失。 123456789101112131415161718192021func publish()&#123;........log.Printf(&quot;enabling publishing confirms.&quot;)if err :&#x3D; channel.Confirm(false); err !&#x3D; nil &#123; return fmt.Errorf(&quot;Channel could not be put into confirm mode: %s&quot;, err)&#125;confirms :&#x3D; channel.NotifyPublish(make(chan amqp.Confirmation, 1))defer confirmOne(confirms).......&#125;func confirmOne(confirms &lt;-chan amqp.Confirmation) &#123; log.Printf(&quot;waiting for confirmation of one publishing&quot;) if confirmed :&#x3D; &lt;-confirms; confirmed.Ack &#123; log.Printf(&quot;confirmed delivery with delivery tag: %d&quot;, confirmed.DeliveryTag) &#125; else &#123; log.Printf(&quot;failed delivery of delivery tag: %d&quot;, confirmed.DeliveryTag) &#125;&#125; 事务机制ACK主要解决问题：消费者从队列中获取到消息后，会直接确认签收，假设消费者宕机或者程序出现异常，数据没有正常消费，这种情况就会出现数据丢失。 思路：设置消费者ack为手动，同时将失败的数据记录到库或者日志，通过定时任务或者人为的方式解决此问题。切记，一定要手动释放掉。","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://logan-liang.github.io/study/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ-数据丢失","slug":"RabbitMQ-数据丢失","permalink":"https://logan-liang.github.io/study/tags/RabbitMQ-%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1/"}]},{"title":"RabbitMQ-延时队列","slug":"RabbitMQ-02","date":"2022-07-05T10:01:50.000Z","updated":"2022-07-05T10:01:50.134Z","comments":true,"path":"2022/07/05/RabbitMQ-02/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/RabbitMQ-02/","excerpt":"","text":"延时队列介绍场景 订单下单之后一定时间未支付会自动取消订单 涉及到T+d（工作日延迟）或者D+d（自然日延迟）等延迟场景 新用户注册之后一个月没下单，发个短信勾引一波 实现RabbitMQ本身不支持延时队列，它是基于存活时间（TTL）和死信交换机（DLE）实现： TTL：可以对队列和消息各自设置存活时间，规则是两者中较小的值，即队列无消费者连接的消息过期时间，或者消息在队列中一直未被消费的过期时间。 DLE：过期的消息通过绑定的死信交换机，路由到指定的死信队列，消费者实际上消费的是死信队列上的消息 延迟组件安装 下载：请到官网去寻找下载地址 启用：rabbitmq-plugins enable rabbitmq_delayed_message_exchange 使用 交换机创建时，Arguments设置为：x-delayed-type:direct 绑定指定queue 程序层 设置header x-deplay:过期时间 注意事项 延时时间的值必须为非负整数。单位为毫秒。 延时时间的最大值为86,400,000，即1天。若延时时间超过最大值，则当作普通消息处理。","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://logan-liang.github.io/study/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ-延时队列","slug":"RabbitMQ-延时队列","permalink":"https://logan-liang.github.io/study/tags/RabbitMQ-%E5%BB%B6%E6%97%B6%E9%98%9F%E5%88%97/"}]},{"title":"RabbitMQ-交换机","slug":"RabbitMQ-01","date":"2022-07-05T10:01:46.000Z","updated":"2022-07-05T10:01:46.285Z","comments":true,"path":"2022/07/05/RabbitMQ-01/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/RabbitMQ-01/","excerpt":"","text":"Fanout exchange -扇形交换机扇形交换机是最基本的交换机类型，他所能做的事情非常简单-广播消息。是所有交换机里面最快的。 Direct exchange -直连交换机是一种带路由功能的交换机，一个队列会和一个交换机绑定，除此之外再绑定一个routing key，当消息被发送的时候，需要指定一个binding_key，这个消息被送达交换机的时候，就会被这个交换机送到指定的队列里面去。同样的一个binding key 也是支持应用到多个队列中的。 使用场景：有优先级的任务，根据任务的优先级把消息发送到对应的队列。 Topic exchange -主题交换机发送到主题交换机上的消息需要携带指定规则的routing_key，主题交换机会根据这个规则将数据发送到对应的队列（多个）上。规则： * 表示一个单词 # 表示任意数量（零个或多个）单词。","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://logan-liang.github.io/study/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ-交换机","slug":"RabbitMQ-交换机","permalink":"https://logan-liang.github.io/study/tags/RabbitMQ-%E4%BA%A4%E6%8D%A2%E6%9C%BA/"}]},{"title":"Git 常用命令","slug":"Git-02","date":"2022-07-05T09:26:34.000Z","updated":"2022-07-05T09:26:34.321Z","comments":true,"path":"2022/07/05/Git-02/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/Git-02/","excerpt":"","text":"git init 初始化本地仓库git remote add origin [Address] 本地仓库与远程仓库关联git remote set-url origin [Address] 本地仓库修改远程仓库关联地址git pull [Address] 获取远程仓库代码git fetch origin 远程仓库代码更新到本地仓库git add &lt;文件&gt; 添加文件到缓存区git commit -m “内容描述” 提交代码 并进行备注git push 上传到远程仓库git branch 查看当前所在分支git branch -r 查看所有分支git branch -a 查看远程分支git branch -d XXXX 删除 分支git tag -a 版本 -m “描述” //打标签git show 版本 //查看标签git push origin 版本 //推送git tag -d 版本 //删除标签git stash //将本地修改代码暂存git stash pop //弹出最近暂存的代码git stash list //查看暂存列表git checkout -b [branchName] //基于当前分支创建并切换新分支git cherry-pick [commitID] //将commit修改内容抽取到当前分支下","categories":[{"name":"Git","slug":"Git","permalink":"https://logan-liang.github.io/study/categories/Git/"}],"tags":[{"name":"Command","slug":"Command","permalink":"https://logan-liang.github.io/study/tags/Command/"}]},{"title":"Git Rebase","slug":"Git-01","date":"2022-07-05T09:26:30.000Z","updated":"2022-07-05T09:26:30.688Z","comments":true,"path":"2022/07/05/Git-01/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/Git-01/","excerpt":"","text":"merge回顾整合分支最容易的方法是merge命令。它会把两个分支的最新快照（C3和C4）以及二者最近的共同祖先（C2）进行三方合并，合并的结果是生成一个新的快照并提交。 rebase介绍如上，你可以提取在C4中引入的补丁和修改，然后在C3的基础上应用一次。这种操作叫做变基（rebase）。你可以使用rebase命令将提交到某一分支上的所有修改都移至另一分支上，就好像”重新播放一样“。 12$ git checkout experiment$ git rebase master 首先找到这两个分支（当前分支experiment， 变基操作的目标分支master）的最近共同祖先C2，然后对比当前分支相对于该祖先的历次提交，提取相应的修改并存为临时文件，然后将当前分支指向目标基底C3，最后一次将之前另存为临时文件的修改依序应用。 命令git rebase -i [startpoint] [endpoint] 合并多个commit为一个完整的commit -i： 代表弹出交互式的界面让用户编辑完成合并操作 [startpoint] ：指定开始编辑区间 [endpoint] ：指定结束编辑区间，若不指定，默认指向的commit pick：保留该commit（缩写:p） reword：保留该commit，但我需要修改该commit的注释（缩写:r） edit：保留该commit, 但我要停下来修改该提交(不仅仅修改注释)（缩写:e） squash：将该commit和前一个commit合并（缩写:s） fixup：将该commit和前一个commit合并，但我不要保留该提交的注释信息（缩写:f） exec：执行shell命令（缩写:x） drop：我要丢弃该commit（缩写:d） git rebase [startpoint] [endpoint] --onto [branchName] 将某一段commit粘贴到另一个分支上 [startpoint] ：指定开始编辑区间 [endpoint] ：指定结束编辑区间，若不指定，默认指向的commit [branchName] : 目标分支 git rebase --onto master feature patch 不合并其他分支，并发布 master：发布至目标 feature：忽略目标 patch：要合并目标 #####git pull --rebase 通过rebase执行git pull","categories":[{"name":"Git","slug":"Git","permalink":"https://logan-liang.github.io/study/categories/Git/"}],"tags":[{"name":"Rebase","slug":"Rebase","permalink":"https://logan-liang.github.io/study/tags/Rebase/"}]},{"title":"Go-GC（垃圾回收）","slug":"go-gc","date":"2022-07-05T09:04:35.000Z","updated":"2022-07-05T09:04:35.198Z","comments":true,"path":"2022/07/05/go-gc/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/go-gc/","excerpt":"","text":"介绍golang的垃圾回收算法使用的是无分代（对象没有代际之分）、不整理（回收过程中不对对象进行移动与整理）、并发（与用户代码并发执行）的三色标记清扫算法。 原理三色标记法将对象分为三类，并用不同的颜色： 白色对象（可能死亡）：未被回收器访问到的对象。在回收开始阶段，所有对象均为白色，当回收结束后，白色对象均不可达。 灰色对象（波面）：已被回收器访问到的对象，但回收器需要堆其中的一个或多个指针进行扫描，因为他是们可能还指向白色对象。 黑色对象（确定存活）：已被回收器访问到的对象，其中所有字段都已被扫描，黑色对象中任何一个指针都不可能直接指向白色对象。 标记过程： 起初所有的对象都是白色的； 从根对象出发扫描所有可达对象，标记为灰色，放入待处理队列； 从待处理队列中取出灰色对象，将其引用的对象标记为灰色并放入待处理队列中，自身标记为黑色； 重复步骤3，直到待处理队列为空，此时白色对象即为不可达的“垃圾”，回收白色对象。 根集合根对象在垃圾回收的术语中又叫根集合，它是垃圾回收器在标记过程时最先检查的对象，包括： 全局变量：程序在编译期就能确定的那些存在于程序整个生命周期的变量。 执行栈：每个groutine都包含自己的执行栈，这些执行栈上包含栈上的变量及指向分配的堆内存区块的指针。 寄存器：寄存器的值可能表示一个指针，参与计算的这些指针可能指向某些赋值器分配的堆内存区块。","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"GC","slug":"GC","permalink":"https://logan-liang.github.io/study/tags/GC/"}]},{"title":"Go-CSP模型","slug":"go-csp","date":"2022-07-05T09:04:30.000Z","updated":"2022-07-05T09:04:30.523Z","comments":true,"path":"2022/07/05/go-csp/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/go-csp/","excerpt":"","text":"CSP并发模型是上个世纪七十年代提出的，用于描述两个独立的并发实体通过共享的通讯channel进行通讯的并发模型，通过共享内存实现并发控制。 golang CSP名言：不要通过共享内存来通信，而是要通过通信来共享内存。 借用CSP模型的一些概念为之实现并发进行理论支持，其实从实际上触发，仅仅借用了process和channel这两个概念。process在go语言上的表现就是goroutine是实际并发执行的实体，每个实体之间是通过channel通讯来实现数据共享。 Channel用于goroutine之间的同步、通信。channel在goroutine间架起了一条管道，在管道里传输数据，实现goroutine间的通信；由于它是线程安全的，所以用起来非常方便；channel还提供“先进先出”的特性；它还能影响goroutine的阻塞和唤醒。 channel分为带缓冲、不带缓冲。 带缓冲：发送方和接收方要同步就绪，只有两者都ready的情况下，数据才能在两者间传输。否则会被阻塞。 不带缓冲：缓冲槽要有剩余容量，操作才会成功，否则会被阻塞。 Goroutine是实际并发执行的实体，他底层是使用协程（coroutine）实现并发，coroutine是一种运行在用户态的用户线程。内存占用为2KB。线程初始为1MB。 特点： 用户空间 避免了内核态和用户态的切换导致的成本 可以由语言和框架层进行调度 更小的栈空间允许创建大量的实例 Goroutine调度器 M：Machine, 代表着一个内核线程，也可以称为系统线程，goroutine跑在M之上的。 P：Processor，处理器，它的主要用途就是用来执行goroutine的，它维护了一组goroutine队列。 G：goroutine，是go语言调度器中待执行的任务，是对Go中代码片段的封装，其实是一种轻量级的用户态线程。 seched：调度器，他维护由存储空闲的M队列和空闲的P队列，可运行的G队列，自由的G队列以及调度器的一些状态信息等。 关系：在Go中，线程（M）是运行goroutine的实体，调度器（P）的功能是把可运行的goroutine分配到工作线程上。 全局队列：存放等待运行的G。 P的本地队列：同全局队列类似，存放的也是等待运行的G，存的数量优先，不超过256个。新建G时，G优先加入到P的本地队列，如果本地队列满了，则会把本地队列中一半的G移动到全局队列。 P列表：所有的P都在程序启动时创建，并保存在数组中，最多有GOMAXPROCS个。 M：线程想运行任务就得获取P，从P的本地队列获取G，P队列为空时，M也会尝试从全局队列拿一批G放到P的本地队列，或从其他P的本地队列拿一半放到自己P的本地队列。M运行G，G执行之后，M会从P获取下一个G，不断重复下去。 调度过程：当一个G被创建的时候，它首先被压入P本地队列，如果P本地满了的情况下，会把本地队列一半的G压入全局队列，所有的P都在程序启动时创建，由默认的GOMAXPROCS个控制，默认是cpu个数。线程想运行任务就得获取P，从P的本地队列获取G，P队列为空时，M也会尝试从全局队列拿一批G放到P的本地队列。M运行G，G执行之后，M会从P获取下一个G，不断重复下去。","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"CSP","slug":"CSP","permalink":"https://logan-liang.github.io/study/tags/CSP/"}]},{"title":"Go-Context","slug":"go-context","date":"2022-07-05T09:04:25.000Z","updated":"2022-07-05T09:04:25.394Z","comments":true,"path":"2022/07/05/go-context/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/go-context/","excerpt":"","text":"context的定义在go语言中用来设置截止日期、同步信号，传递请求相关值得结构体。其中包括： Deadline-返回context.Context被取消的时间，也就是完成工作的截止时间。 Done-返回一个Channel，这个Channel会在当前工作完成或者上下文被取消后关闭，多次调用Done方法会返回同一个Channel； Err-返回context的结束原因，它只会在Done方法对应的Channel关闭时返回非空的值；取消-返回canceld错误；超时-返回DeadlineExceeded错误。 Value-从context中获取键对应的值，对于同一个上下文来说，多次调用Value并传入相同的Key会返回相同的结果。 设计原理目的：在Goroutine构成的树形结构中对信号进行同步以减少计算资源的浪费。 如果创建多个Goroutine来处理一次请求，而context的作用是在不同的Goroutine之间同步请求特定数据、取消信号以及处理请求的截止日期。 每一个context都会从最顶层的Goroutine一层一层传递到最下层。context可以在上层Goroutine执行出现错误时，将信号及时同步给下层。 相关函数1、context.WithCancel：返回一个可以手动取消的Context，可以手动调用cancel()方法以取消该context。2、context.WithDeadline &amp; context.WithTimeout：可以自定义超时时间，时间到了自动取消context。其实withTimeout就是对WithDeadline的一个封装。3、context.WithValue：可以传递数据的context，携带关键信息，为全链路提供线索。","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"Context","slug":"Context","permalink":"https://logan-liang.github.io/study/tags/Context/"}]},{"title":"Go-Channel","slug":"go-channel","date":"2022-07-05T09:04:18.000Z","updated":"2022-07-05T09:04:18.386Z","comments":true,"path":"2022/07/05/go-channel/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/go-channel/","excerpt":"","text":"Channel数据结构1234567891011121314151617181920212223type hchan struct &#123; &#x2F;&#x2F;channel分为无缓冲和有缓冲两种。 &#x2F;&#x2F;对于有缓冲的channel存储数据，借助的是如下循环数组的结构 qcount uint &#x2F;&#x2F; 循环数组中的元素数量 dataqsiz uint &#x2F;&#x2F; 循环数组的长度 buf unsafe.Pointer &#x2F;&#x2F; 指向底层循环数组的指针 elemsize uint16 &#x2F;&#x2F;能够收发元素的大小 closed uint32 &#x2F;&#x2F;channel是否关闭的标志 elemtype *_type &#x2F;&#x2F;channel中的元素类型 &#x2F;&#x2F;有缓冲channel内的缓冲数组会被作为一个“环型”来使用。 &#x2F;&#x2F;当下标超过数组容量后会回到第一个位置，所以需要有两个字段记录当前读和写的下标位置 sendx uint &#x2F;&#x2F; 下一次发送数据的下标位置 recvx uint &#x2F;&#x2F; 下一次读取数据的下标位置 &#x2F;&#x2F;当循环数组中没有数据时，收到了接收请求，那么接收数据的变量地址将会写入读等待队列 &#x2F;&#x2F;当循环数组中数据已满时，收到了发送请求，那么发送数据的变量地址将写入写等待队列 recvq waitq &#x2F;&#x2F; 读等待队列 sendq waitq &#x2F;&#x2F; 写等待队列 lock mutex &#x2F;&#x2F;互斥锁，保证读写channel时不存在并发竞争问题&#125; 过程详解先入先出目前的Channel收发操作均遵循了先进先出的设计，具体规则如下： 先从Channel读取数据的Goroutine会先接收到数据； 先向Channel发送数据的Goroutine会得到先发送数据的权利； 发送步骤： 锁定整个hchan通道结构。 确定发送，recvq不为空，将元素直接写入goroutine同时挂起，等待被唤醒；recvq为空，则确定缓冲区是否可用，如果可用，则把数据写到缓冲区中；如果缓冲区满了，则把当前数据写入goroutine，并且当前goroutine保存在sendq中，进入休眠，等待被唤醒。 写入完成释放锁。 读取步骤： 先获取hchan全局锁。 尝试从sendq队列中获取数据。 如果sendq不为空且没有缓冲区，取出g并读取数据，然后唤醒g，结束读取； 如果sendq为空且有缓冲区，从缓冲区队列获取数据，再从sendq取出g，将g中的数据存放到buf队列尾； 如果sendq不为空且有缓冲区，直接读取缓冲区数据； 如果sendq为空且没有缓冲区，将当前goroutine加入到sendq队列，进入睡眠，等待被写入goroutine唤醒。 结束读取释放锁。","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"Channel","slug":"Channel","permalink":"https://logan-liang.github.io/study/tags/Channel/"}]},{"title":"Redis-缓存防坑指南","slug":"Redis-05","date":"2022-07-05T08:33:53.000Z","updated":"2022-07-05T08:33:53.660Z","comments":true,"path":"2022/07/05/Redis-05/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/Redis-05/","excerpt":"","text":"redis缓存击穿（失效）名词解释高并发流量，访问的这个数据是热点数据，请求的数据在DB中存在，但是Redis存的那一份已经过期，后期需要从DB中加载数据写到Redis。关键字：单一热点数据、高并发、数据失效。但是由于高并发，可能会把DB压垮，导致服务不可用。 解决方案 过期时间+随机值让数据在未来一段时间内慢慢过期，避免瞬时全部过期，对DB造成过大压力。 预热预先把数据提前存入，并设置热门数据的过期时间超大值。 使用锁当发现缓存失效的时候，不是立即从数据库加载数据。先获取分布式锁，获取锁成功才执行数据库查询和写入的操作，获取锁失败，说明已被占用，让线程睡眠一段时间在重试。 缓存穿透名词解释意味着有特殊请求在查询一个不存在的数据，即数据不存在Redis也不存在于数据库。导致每次请求都会穿透到数据库，缓存成了摆设，对数据库产生很大压力从而影响正常服务。 解决方案 缓存空值设置一个缺省值（比如：None）。当后续再次进行查询则直接返回控制或者缺省值。 布隆过滤器在数据写入数据库的同时这个ID同步到布隆过滤器中，当请求的id不存在布隆过滤器中则说明一定没有写入数据库，就不要去数据库查询了。 缓存雪崩名词解释大量的请求无法在Redis缓存系统中处理，请求全部达到数据库，导致数据库压力激增，甚至宕机。 出现原因 大量热点数据同时过期，导致大量请求需要查询数据库并写到缓存；解决方案：过期时间添加随机值；接口限流； Redis故障宕机，缓存系统异常。解决方案：服务熔断和限流构建高可用的缓存集群 服务熔断：就是当从缓存获取数据发现异常，则直接返回错误数据给前端，防止所有流量打到数据库导致宕机。","categories":[{"name":"Redis","slug":"Redis","permalink":"https://logan-liang.github.io/study/categories/Redis/"}],"tags":[{"name":"Redis-缓存","slug":"Redis-缓存","permalink":"https://logan-liang.github.io/study/tags/Redis-%E7%BC%93%E5%AD%98/"}]},{"title":"Redis-持久化存储","slug":"Redis-04","date":"2022-07-05T08:33:50.000Z","updated":"2022-07-05T08:33:50.382Z","comments":true,"path":"2022/07/05/Redis-04/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/Redis-04/","excerpt":"","text":"持久化方案redis作为一个内存数据库，数据是以内存为载体存储的，那么一旦reids服务器进程退出，服务器中的数据也会消息。为了解决这个问题，redis提供了持久化机制，包括:RDB持久化：以快照的方式AOF持久化：日志追加的方式。 RDB快照持久化即在指定的时间间隔内将内存中的数据集快照写入磁盘。在创建快照之后，用户可以备份该快照，可以将快照复制到其他服务器以创建相同的数据副本。该方案是redis默认的。 RDB持久化生成RDB文件，该文件是一个压缩过的二进制文件，默认为当前工作目录下的dump.rdb，可以根据配置文件中的dbfilename和dir设置RDB文件名和文件位置。 触发快照时机 执行save和bgsave命令 配置文件设置 save 规则，自动间隔执行bgsave命令 主从复制时，从库全量复制同步主库数据，主库会执行bgsave 执行flushall 命令清空服务器数据 执行shutdown命令关闭redis时，会执行save命令 save和bgsave命令 使用save 命令会阻塞redis服务器进行，服务器进程在RDB文件创建完成之前是不能处理任何的命令请求。 bgsave命令会fork一个子进程，然后该子进程会负责创建RDB文件，而服务器进程会继续处理命令请求。","categories":[{"name":"Redis","slug":"Redis","permalink":"https://logan-liang.github.io/study/categories/Redis/"}],"tags":[{"name":"Redis-持久化","slug":"Redis-持久化","permalink":"https://logan-liang.github.io/study/tags/Redis-%E6%8C%81%E4%B9%85%E5%8C%96/"}]},{"title":"Redis-淘汰机制","slug":"Redis-03","date":"2022-07-05T08:33:46.000Z","updated":"2022-07-05T08:33:46.977Z","comments":true,"path":"2022/07/05/Redis-03/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/Redis-03/","excerpt":"","text":"redis过期删除一般会对数据设置过期时间，使得这些缓存在过期后能被清楚，释放缓存资源。目前主要有两种方式： 定期删除 redis每过100ms，从设置了过期时间的key中随机取出20个缓存key 清除其中的过期key 若过期key占比超过1/4，则重复步骤（1） 惰性删除某个缓存key在查询时，若此时已过期，则会从缓存中删除，同时返回空 以上两种会同时进行，但会出现一种问题：部分过期缓存key未被清理，长久占用资源，随着缓存数据的不断增加，无法通过删除key来释放资源，存储新的资源。就会利用内存淘汰机制来实现。 内存淘汰机制 noeviction：返回错误，不删除任何键值 allkeys-lru：尝试回收最少使用的键值（LRU算法） volatile-lru：尝试回收最少使用的键值，但仅限于在过期键值集合中 allkeys-random：回收随机的键值 volatile-random：回收随机的键值，并优先回收存活时间较短的键值 volatile-ttl：回收过期集合的键值，并优先回收存活时间较短的键值 allkeys-lfu：回收最少使用频次的键值（LFU算法） volatile-lfu：回收最少使用频次的键值（LFU算法），但仅限于过期键值集合中 这里有两个重要的算法：LRU：最近最少被使用。访问时间越早越容易被淘汰LFU：最近最少使用频次。使用频次越少越容易被淘汰","categories":[{"name":"Redis","slug":"Redis","permalink":"https://logan-liang.github.io/study/categories/Redis/"}],"tags":[{"name":"Redis-淘汰机制","slug":"Redis-淘汰机制","permalink":"https://logan-liang.github.io/study/tags/Redis-%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6/"}]},{"title":"Redis-分布式锁","slug":"Redis-02","date":"2022-07-05T08:33:43.000Z","updated":"2022-07-05T08:33:43.771Z","comments":true,"path":"2022/07/05/Redis-02/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/Redis-02/","excerpt":"","text":"基于SETNX、EXPIRE实现锁语法set key value nx ex timeOut NX：只有这个key不存在的时候才会进行操作，即 if not existsEX：设置key的过期时间为秒，具体时间由第五个参数决定timeOut：设置过期时间保证不会出现死锁 原理总的来说，执行上面的set 会导致两种结果：1、当前没有锁（key不存在），那么就进行加锁操作，并对锁设置个有效期，同时value表示加锁的客户端。2、已有锁存在，不做任何操作。 基于 redisson实现分布式锁什么是redisson？是一个redis的基础上实现的java常驻内存数据网络。就是在redis的基础上封装了很多功能，以便于我们更方便的使用。 加锁流程客户端N-&gt;获取锁-&gt;加锁成功（如失败继续获取锁）-&gt;看门狗-&gt;redis分布式节点存储 语法lock=redisson.getLock(“myLock”)；lock.lock();//加锁lock.unlock(); //解锁 互斥锁假如客户A已经拿到了myLock，现在有客户B想进入： 判断是否存在锁 判断客户端A重新请求，证明当前是同一个客户端同一个线程重新进入，标志+1，重新刷新生存时间（可重入），否则进入下一个if。 客户端B会获取到pttl mylock返回的一个数字，这个数字代表mylock这个锁key的剩余生存时间。此时客户端B会进入一个while循环，不停的尝试加锁。 watch dog 看门狗可以自定义设置看门狗的监控超时时间。如果还没执行完毕，监听到这个客户端A的线程还持有锁，就去续期，默认是10秒监听一次，如果还持有，就不断的延长锁的有效期。 分布式锁的缺点如果是主从、哨兵模式，当客户端A把myLock 这个锁的key的value写入了master，此时会异步复制给slave实例。万一在这个主从复制的过程中master宕机了，主备切换，slave变成了master。那么这个时候slave还没来得及加锁，此时客户端A的myLock的值是没有的，客户端B在请求时，myLock却成功为自己加了锁。这时候分布式锁就失效了，就会导致数据有问题。所以说redis分布式锁最大的缺点就是宕机导致多个客户端加锁，导致脏数据，这种几率还是很小的。 防坑指南 setnx 需要同时设置 nx ex ，不然会导致 非同步，加锁混乱的情况 setnx的值 必须作为唯一凭证，最后销毁锁的时候校验当前锁是否是要销毁的","categories":[{"name":"Redis","slug":"Redis","permalink":"https://logan-liang.github.io/study/categories/Redis/"}],"tags":[{"name":"Redis-分布式锁","slug":"Redis-分布式锁","permalink":"https://logan-liang.github.io/study/tags/Redis-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"}]},{"title":"Redis-数据类型","slug":"Redis-01","date":"2022-07-05T08:33:40.000Z","updated":"2022-07-05T08:33:40.808Z","comments":true,"path":"2022/07/05/Redis-01/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/Redis-01/","excerpt":"","text":"字符串语法 set key value ex second get key exists key解释string采用的数据结构为SDS（simple dynamic string），中文为简单动态字符串。一共有三个属性，包括：len：字符串的长度free：记录buf数组未使用的字节数量buf：buf数组。 列表 list语法 rpush key value //从右侧插入数据 lpush key value //从左侧插入数据 lrange key start stop //随机获取数据 rpop key //从右侧弹出一个数据 lpop key //从左侧弹出一个数据 llen key //统计列表长度 解释列表采用的数据结构为Linked List（链表）。 哈希 hash语法 hdel key field1 field2 //删除一个或多个哈希表字段 hexists key field //查看哈希表key中，指定的字段是否存在 hget key field //获取哈希表中的字段的值 hgetall key //获取哈希表中key的所有字段和值 hincrby key field increment //哈希表key中的指定字段的整数值加上增量increment hincrbyfloat key field increment //哈希表key中的指定字段的浮点数值加上增量increment hkeys key //获取所有哈希表中的字段 hlen key //获取哈希表中字段的数量 hmget key field1 field2 //获取所有给定字段的值 hmset key field1 value2 //将多个field value对设置到哈希表key中 hset key field value //将哈希表key中的字段field 值设为value hsetnx key field value //只有字段field不存在时，设置哈希表字段的值 hvals key //获取哈希表中所有值。 hscan key cursor //迭代哈希表中的键值对 解释它的主要目的时加快查找指定key的速度，无论hashTable中有多少元素，它的查找效率为o(1)时间复杂度，无需遍历，直接定位到元素。数据结构采用数组+链表的数据结构，数组时第一维，链表是第二维。数组中的每个元素称为槽或者桶，存储着链表的第一个元素的指针。当多个key值的摘要取模后相等时，就会使用链表进行串联依次存储key值，这种情况称为散列冲突，也叫碰撞。 集合 Set语法sadd key m1 m2 //向集合添加一个或者多个成员scard key //获取集合的成员数sdiff key1 key2 //返回第一个集合与其他集合之间的差异sdiffstore destination key1 key2 //返回给定所有集合的差集并存储在destination中sinter key1 key2 //返回给定所有集合的交集sinterstore destination key1 key2 //返回给定所有集合的交集并存储在destination中sismember key member //判断member元素是否是集合key的成员smembers key //返回集合中的所有成员smove source destination member //将member元素从source集合移动到destination集合spop key //移除并返回集合中的一个随机元素srandmember key //返回集合中一个或多个随机数srem key member1 member2 //一处集合中一个或多个成员sunion key1 key2 //返回所有给定集合的并集sunionstore destination key1 key2 //所有给定集合的并集存储在destination集合中sscan key cursor 迭代集合中的元素 解释集合是string类型的无序集合。集合成员是唯一的，是通过哈希表实现的，查找的复杂度都是o(1)。集合中最大的成员数为2的32次方 -1，每个集合可存储40多亿个成员。 有序集合 sorted set语法zadd key score1 member1 //想有序集合添加一个或多个成员，或者更新已存在成员的分数zcard key //获取有序集合的成员数zcount key min max //计算在有序集合中指定区间分数的成员数zincrby key increment member //有序集合中对指定成员的分数机上增量incrementzinterstore destination numkeys key //计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 destination 中zlexcount key min max //在有序集合中计算指定字典区间内的成员数量zrange key start stop //通过索引区间返回有序集合指定区间内的成员zrangebylex key min max //通过字典区间返回有序集合的成员zrangebyscore key min max //通过分数返回有序集合指定区间内的成员zrank key member //返回有序集合中指定成员的索引zrem key member //移除有序集合中的一个或多个成员zremrangebylex key min max //移除有序集合中给定的字典区间的所有成员zremrangebyrank key start stop //移除有序集合中给定的排名区间的所有成员zremrangebyscore key min max //移除有序集合中给定的分区区间的所有成员zrevrange key start stop //返回有序集合中指定分数区间内的成员，分数从高到底排序zrevrank key member //返回有序集合中指定成员的排名，有序集合成员按分数值递减排序zscore key member //返回有序集合，成员的分数值zunionstore destination numkeys key //计算给定的一个或多个有序集的并集，并存储在新的key中zscan key cursor //迭代有序集合中的元素 解释集合是通过哈希表实现的，查找的复杂度都是O(1)。","categories":[{"name":"Redis","slug":"Redis","permalink":"https://logan-liang.github.io/study/categories/Redis/"}],"tags":[{"name":"Redis-数据类型","slug":"Redis-数据类型","permalink":"https://logan-liang.github.io/study/tags/Redis-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"}]},{"title":"MySQL-Query Cache","slug":"Mysql-08","date":"2022-07-05T07:42:42.000Z","updated":"2022-07-05T07:42:42.337Z","comments":true,"path":"2022/07/05/Mysql-08/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/Mysql-08/","excerpt":"","text":"MySQL查询缓存介绍是MySQL中比较独特的一个缓存区域，用来缓存特定Query的整个结果集信息，且共享给所有客户端。为了提高完全相同的Query语句的响应速度，MySQL会对查询语句进行Hash计算后，把得到的hash值与Query查询的结果集对应存放在Query Cache中。当打开Query Cache之后，MySQL会对接收到的每一个SELECT语句通过特定的HASH计算该Query的HASH值，然后通过该HASH值到Query Cache中去匹配。 如果没有匹配，将这个hash值存放在一个hash链表中，并将Query的结果集存放到cache中，存放hash值链表的每个hash节点存放了相应Query结果集在Cache中的覅之，以及该query所涉及到一些table的相关信息。 如果通过hash值匹配到了一样的Query，则直接将cache中相应的query结果集返回给客户端。 MySQL缓存机制如果运行相同的SQL，服务器直接从缓存中取到结果，不需要在去解析和执行SQL。如果表更改了，那么使用这个表的所有缓存查询将不再有效，查询缓存中值相关条目被清空。更改指的是表中任何数据或是结构发生改变。显然，这对于频繁更新的表，查询缓存时不适合的，而对于一些不常改变数据且大量相同SQL查询的表，查询缓存会节约很大的性能。 缓存规则 太大的result set不会被cache MySQL缓存在分库分表环境下是不起作用 执行SQL里有触发器，自定义函数时，MySQL缓存也是不起作用的 缓存失效 在表的结构或数据发生改变时，查询缓存中的数据不再有效，如 insert、update、delete等。所以查询缓存适合大量相同查询的应用，不适合大量数据更新的应用。 一旦表数据进行任何一行的修改，基于该表相关cache立即全部失效。 手动清理缓存 FLUSH QUERY CACHE：清理查询缓存内部碎片 RESET QUERY CACHE：从查询缓存中移除所有查询 FLUSH TABLES：关闭所有打开的表，同时该操作会清空查询缓存中的内容 缺点 查询语句的hash计算和hash查找带来的资源消耗。如果将type设置为on，那么mysql会对每条接收到的select类型的查询进行hash计算，然后查找这个查询缓存结果是否存在。如果成千上万条查询语句时，hash计算和查找所带来的开销就会很大。 query cache的失效问题。如果表的变更比较频繁，则会造成Query Cache的失效率非常高。如果缓存大，消耗也大。可将死一段时间，因为这个操作是靠全局锁来保护。 查询语句不同，但查询结果相同的查询都会被缓存，这样便会造成内存资源的过度消耗。查询语句的字符大小写、空格或者注释的不同，Query Cache都会认为是不同的查询。 相关系统变量设置不合理会造成大量的内存碎片，这样便会导致Query Cache频繁清理内存。 MySQL8.0 取消缓存的原因 查询缓存的效果取决于缓存的命中率，只有命中缓存的查询效果才能有改善，因此无法预测其性能。 查询缓存的另一个大问题是它受到单个互斥锁的保护。在具有多个内核的服务器上，大量查询会导致大量的互斥锁争用。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://logan-liang.github.io/study/categories/MySQL/"}],"tags":[{"name":"MySQL缓存","slug":"MySQL缓存","permalink":"https://logan-liang.github.io/study/tags/MySQL%E7%BC%93%E5%AD%98/"}]},{"title":"MySQL-通信过程","slug":"Mysql-07","date":"2022-07-05T05:51:03.000Z","updated":"2022-07-05T05:51:03.204Z","comments":true,"path":"2022/07/05/Mysql-07/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/Mysql-07/","excerpt":"","text":"基本介绍MySQL基于tcp的底层协议，需要经历tcp的三次握手。 交互过程握手阶段 服务器-&gt;客户端：握手初始消息 客户端-&gt;服务器：登录认证 服务器-&gt;客户端：认证结果命令执行阶段 客户端-&gt;服务器：执行命令消息 服务器-&gt;客户端：命令执行结果 报文解读登录认证报文握手初始化报文 协议版本号：服务端所使用的mysql协议的版本号 服务器线程ID：服务端为此客户端所创建的线程ID 挑战随机数：MySQL数据库用户认证采用的是挑战/应答的方式，服务器生成该挑战数并发送给客户端，由客户端进行处理并返回相应结果，然后服务器检查是否与预期的结果相同，从而完成用户认证的过程。 服务器权能标志：用于与客户端协商通讯方式 登录认证报文 客户端全能标志：客户端收到服务器发来的初始化报文后，会对服务器发送的全能标志进行修改，保留自身所支持的功能，然后将全能标志返回给服务器，从而保证服务器与客户端通讯的兼容性。 消息长度：客户端发送请求时所支持的最大消息长度值 字符编码：表示通讯过程中使用的字符编码，与服务器在认证报文中发送的相同 用户名：客户端登录的用户名 挑战认证数据：客户端用户密码使用服务器发送的挑战随机数进行加密后，生成挑战认证数据，返回给服务器用于服务端的认证。 服务端认证结果报文服务端主要验证用户名、密码是否正确存在，如果正确返回ok，否则返回error报文。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://logan-liang.github.io/study/categories/MySQL/"}],"tags":[{"name":"MySQL通信过程","slug":"MySQL通信过程","permalink":"https://logan-liang.github.io/study/tags/MySQL%E9%80%9A%E4%BF%A1%E8%BF%87%E7%A8%8B/"}]},{"title":"MySQL-性能指标","slug":"Mysql-06","date":"2022-07-05T05:50:59.000Z","updated":"2022-07-05T05:50:59.110Z","comments":true,"path":"2022/07/05/Mysql-06/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/Mysql-06/","excerpt":"","text":"QPS 每秒查询率QPS：Queries Per Second ，是一台服务器每秒能够相应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。 TPS 每秒事务TPS：Transaction Per Second，也就是事务数/秒。它是软件测试结果的测量单位。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。 RT，响应时间RT：Respnse Time。执行一个请求从开始到最后收到响应数据所花费的总体时间，是一个系统最重要的指标之一，它的数值大小直接反应了系统的快慢。 并发数并发数是指系统同时处理的请求数量，反应系统的负载能力。 吞吐量吞吐量（承压能力）与request对CPU消耗、外部接口、IO等等紧密关联。几个重要参数：QPS、并发数、响应时间。QPS（TPS）=并发数/平均响应时间并发数=QPS*平均响应时间 公式：按照二八定律来区分。（总PV数80%）/(每天秒数20%)=峰值时间每秒请求数（QPS） 峰值时间每秒QPS/单台机器QPS=需要的机器","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://logan-liang.github.io/study/categories/MySQL/"}],"tags":[{"name":"MySQL性能指标","slug":"MySQL性能指标","permalink":"https://logan-liang.github.io/study/tags/MySQL%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/"}]},{"title":"MySQL-插入原理","slug":"Mysql-05","date":"2022-07-05T05:50:55.000Z","updated":"2022-07-05T05:50:55.298Z","comments":true,"path":"2022/07/05/Mysql-05/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/Mysql-05/","excerpt":"","text":"innodb写入流程1、在数据要被写入或者修改时，一定要查找到该数据所位于的page（数据操控的最小单位），如果page没有位于buffer pool，会发生缺页中断，加载磁盘上的page到buffer pool中。2、查找到page以后，先要保存当前数据到undo log日志（为了事务回滚后，数据也能回滚）。3、直接修改page 上的数据，buffer pool中的脏页达到一定比例时，会进行刷盘操作。4、记录redo log 日志，用于事务的持久化。5、如果开启binlog，也会触发一个redo log 和binlog的二阶段提交。 redo log用于保证innodb事务的持久性，在宕机的情况下，根据日志文件进行数据重做，将数据恢复到宕机或者断电前的状态，保证了更新的数据不丢失。它的本质是保证事务提交后，更新的数据不丢失。 undo logundolog会保留每行数据一段时间内所有事务的操作记录，用于进行事务回滚以及帮助mvcc进行事务隔离。mysql会定时获取当前所有readview中最老的事务id，并使用purge线程将该事务之前的undolog 进行回收。 redo、bin log 双写一致性innodb采用了二阶段提交，来保障redo和bin log 的一致性。 1、先写入redolog日志，生成事务标记xid，并设置状态为prepare状态。2、写入binlog日志3、进行事务提交，更改xid的redolog变成commit状态。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://logan-liang.github.io/study/categories/MySQL/"}],"tags":[{"name":"MySQL插入","slug":"MySQL插入","permalink":"https://logan-liang.github.io/study/tags/MySQL%E6%8F%92%E5%85%A5/"}]},{"title":"MySQL-索引原理","slug":"Mysql-01","date":"2022-07-05T01:40:03.000Z","updated":"2022-07-05T02:47:26.597Z","comments":true,"path":"2022/07/05/Mysql-01/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/Mysql-01/","excerpt":"","text":"索引目的提高查询效率。 索引原理数据库实现比较复杂，数据保存在磁盘上，而为了提高性能，每次又可以把部分数据读入内存计算，因为我们直到访问磁盘的成本大概是访问内存的十万倍左右，所以简单的搜索树难以满足复杂的应用场景。 磁盘IO与预读磁盘读取数据靠的是机械运动，每次读取数据花费的时间可以分为寻道时间、旋转延迟、传输时间三个部分。 寻道时间指的是磁臂移动到指定磁道所需要的时间，主流磁盘一般在5ms以下； 旋转延迟就是我们经常听说的磁盘转速，比如一个磁盘7200转，表示每分钟能转7200次，也就是说1秒钟能转120次，旋转延迟就是1/120/2=4.17ms; 传输时间指的是从磁盘读出或将数据写入磁盘的时间，一般在零点几毫秒，相对于前两个时间可以忽略不计。 那么访问一次磁盘的时间，即一次磁盘IO的时间约等于5+4.17=9ms左右，如果执行一次IO的时间可以执行40万条指令，数据库动辄十万百万乃至千万级数据，每次9毫秒时间，显然是个灾难。 考虑到磁盘IO是非常高昂的操作，计算机操作系统做了一些优化，当一次IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，因为局部预读性原理告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问。每一次IO读取的数据我们称之为一页。具体一页有多大数据跟操作系统有关，一般为4K或8K，也就是我们读取一页内的数据时候，实际上才发生了一次IO。 索引数据结构-B+树每个磁盘块包含几个数据项和指针，如磁盘块1包含数据项17和35，包含指针p1、p2、p3，P1表示小于17的磁盘块，p2表示在17和35之间的磁盘块，p3表示大于35的磁盘块。真实的数据存在于叶子节点，非叶子节点只存储指引搜索方向的数据项。 B+树的查找过程如以上例子所示，如果要查找数据项，首先会把磁盘块A由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定数据位置，锁定磁盘块A的指针，反复操作，直到找到数据为止。三层的B+树可以表示上百万的数据，如果上百万的数据查找只需要三次IO，性能提高将是巨大的。没有索引每个数据项发生一次IO，成本非常高。 B+树性质 通过上面的分析，我们知道IO次数取决于B+树的高度，假设当前数据表的数据为N，每个磁盘块的数据项的数量是m，则有h=㏒(m+1)N，当数据量N一定的情况下，m越大，h越小；而m = 磁盘块的大小 / 数据项的大小，磁盘块的大小也就是一个数据页的大小，是固定的，如果数据项占的空间越小，数据项的数量越多，树的高度越低。这就是为什么每个数据项，即索引字段要尽量的小，比如int占4字节，要比bigint8字节少一半。这也是为什么b+树要求把真实的数据放到叶子节点而不是内层节点，一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。 当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，b+数是按照从左到右的顺序来建立搜索树的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即索引的最左匹配特性。 慢查询优化建立索引的原则 最左前缀匹配原则，非常重要的原则，mysql会一直项右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配。 =和in可以乱序，mysql的查询优化器会帮我们优化成可以识别的形式。 尽量选择区分度高的列作为索引，区分度的公式:count(distinct col)/count(*)。表示字段不重复的比例，比例越大我们扫描的记录数越小。 索引列不能参与计算，保持列“干净”。 尽量的扩展索引，不要新建索引。意思就是建立复合索引。 查询优化神器-explain命令这里需要强调的是rows是核心指标，绝大部分rows小的语句一定很快。所以优化语句基本上都是在优化rows。 慢查询优化基本步骤 先运行看看是否真的很慢，注意设置SQL_NO_CACHE where条件单表查，锁定最小返回记录表。 explain查看执行计划，是否与预期一致。 order by limit 形式的sql语句让排序的表优先查 了解业务使用场景 加索引时参照建索引的几大原则 观察结果，不符合预期继续从0分析","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://logan-liang.github.io/study/categories/MySQL/"}],"tags":[{"name":"MySQL索引","slug":"MySQL索引","permalink":"https://logan-liang.github.io/study/tags/MySQL%E7%B4%A2%E5%BC%95/"}]},{"title":"MySQL-存储引擎","slug":"Mysql-02","date":"2022-07-05T01:40:03.000Z","updated":"2022-07-05T02:55:59.505Z","comments":true,"path":"2022/07/05/Mysql-02/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/Mysql-02/","excerpt":"","text":"InnoDB 存储引擎InnoDB时事务型数据库的首选引擎，支持事务安全表（ACID），支持行锁定和外键，是默认的MySQL引擎。特性：（1）为MySQL提供了具有提交、回滚和崩溃恢复能力的事务安全机制。InnoDB锁定在行级并且也在select语句提供一个类似Oracle的非锁定读。（2）在主内存中缓存数据和索引而维持它自己的缓冲池。（3）支持外键完整性约束。 使用该引擎 MySQL将在目录下创建一个名为ibdata1的10MB大小的自动扩展数据文件，以及两个名为ib_logfile0和ib_logfile1的5MB大小的日志文件。 该引擎不保存表的具体行数，也就是说 select count (*) from table 时，要扫描一遍整个表来计算有多少行。 MyISAM存储引擎基于ISAM存储引擎，并对其进行扩展。拥有较高的插入、查询速度，但不支持事务。 特性：（1）被大文件系统和操作系统支持（2）当把删除和更新及插入操作混合使用时的时候，动态储存的行产生更少碎片。（3）每个MyISAM表最大索引数是64，这可以通过重新编译来改变。（4）最大的键长度是1000字节，可以通过编译来改变。（5）BLOB和TEXT列可以被索引（6）NULL被允许在索引的列中，这个值占每个键的0-1个字节。（7）所有数字键值以高字节优先被存储以允许一个更高的索引压缩（8）每个MyISAM类型的表都有一个auto_increment的内部列，当插入和更新操作的时候列被更新，同时auto_increment列将被刷新。（9）可以把数据文件和索引文件放在不同的目录（10）每个字符列可以有不同的字符集（11）有varchar的表可以固定和动态记录长度（12）varchar和char列可以多达64kb 使用该引擎创建数据库，将产生3个文件。文件的名字以表名字开始，扩展名之处文件类型：frm文件存储表定义、数据文件得扩展名为.MYD、索引文件得扩展名为.MYI。 该引擎强调快速读取操作。它存储表的行数，SELECT COUNT (*) FROM TABLE 时只需要直接读取已经保存号的值。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://logan-liang.github.io/study/categories/MySQL/"}],"tags":[{"name":"MySQL存储引擎","slug":"MySQL存储引擎","permalink":"https://logan-liang.github.io/study/tags/MySQL%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"}]},{"title":"MySQL-锁","slug":"Mysql-04","date":"2022-07-05T01:40:03.000Z","updated":"2022-07-05T05:50:50.722Z","comments":true,"path":"2022/07/05/Mysql-04/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/Mysql-04/","excerpt":"","text":"种类乐观锁用数据版本记录机制实现，这是乐观锁最常用的一种实现方式。 悲观锁指的是在操作数据时，认为此操作会出现冲突，所以在进行每次操作时都要通过获取锁才能进行对相同数据的操作。 共享锁（读锁，lock in share mode）是读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改，直到已释放所有共享锁。当事务对读锁进行修改操作，很可能会造成死锁。 排他锁（写锁 for update）若某个事务对某一行加上了排他锁，只能对这个事务进行读写，在此事务结束之前，其他事务不能对其进行加任何锁，其他进程可以读取，但不能写操作，需等待其释放。 锁级别表级锁开销小，加锁快；不会出现死锁；锁定力度大，发生锁冲突的概率最高，并发度低。表锁使用的是一次性锁技术，在会话开始的地方使用lock命令将后续需要用到的表都加上锁，在表释放前，只能访问这些加锁的表，不能访问其他表，直到最后通过 unlock tables 释放锁。除了unlock tables显示释放锁之外，会话持有其他表锁时执行lock table语句会释放会话之前持有的锁；会话持有其他表锁时执行 start transaction 或者begin开启事务时，也会释放之前持有的锁。 行级锁开销大，加锁慢；会出现死锁；锁定力度最小，发生锁冲突的概率最低，并发度也最高。 InnoDB锁特性 在不通过索引条件查询的时候，InnoDB使用的是表锁。 由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的。 当表有多个索引的时候，不同的事务可以是同不同的索引锁定不同的行，不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁。 即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，这种情况下将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查SQL的执行计划explain。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://logan-liang.github.io/study/categories/MySQL/"}],"tags":[{"name":"MySQL锁","slug":"MySQL锁","permalink":"https://logan-liang.github.io/study/tags/MySQL%E9%94%81/"}]},{"title":"MySQL-事务与隔离级别","slug":"Mysql-03","date":"2022-07-05T01:40:03.000Z","updated":"2022-07-05T05:50:47.379Z","comments":true,"path":"2022/07/05/Mysql-03/","link":"","permalink":"https://logan-liang.github.io/study/2022/07/05/Mysql-03/","excerpt":"","text":"事务事务（Transaction）是访问和更新数据库的程序执行单元；事务中包含一个或多个sql语句，这些语句要么都执行，要么都不执行。 ACID原子性是指一个事务时一个不可分割的工作单位，其中的操作要么都做，要么都不做 在说明原理之前，首先介绍一下MySQL的事务日志，如二进制日志、错误日志、查询日志、慢查询日志等，此外InnoDB存储引擎还提供了两种事务日志：redo log（重做日志）和undo log（回滚日志）。其中redo log 用于保证事务持久性；undo log则是事务原子性和隔离性的实现基础。 InnoDB实现回滚，靠的是undo log：当事务对数据库进行修改时，InnoDB会生成对应的undo log；如果事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子 持久性是指一旦事务提交，他对数据库的改变就应该是永久性的。InnoDB作为MySQL的存储引擎，数据是存放在磁盘中的，但如果每次读写数据都需要磁盘IO，效率很低。为此，InnoDB提供了缓存（Buffer pool），Buffer Pool中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲：当从数据库读取数据时，会首先从Buffer Pool中读取，如果Buffer Pool中没有，则从磁盘读取后放入Buffer Pool；当向数据库写入数据时，会首先写入Buffer Pool，BufferPool中修改的数据会定期刷新到磁盘中。 buffer Pool的使用大大提高了读写数据的效率，但也带来了新的问题，如果mysql宕机，而此时Buffer Pool中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证。 于是，redo log被引来解决这个问题：当数据修改时，除了修改Buffer Pool中的数据，还会在redo log记录这次数据；当事务提交时，会调用fsync接口对redo log 进行刷盘。如果mySQL宕机，重启时可以读取redo log中的数据，对数据库进行恢复。redo log 采用的时WAL（write-ahead loggong，预写式日志），所有修改先写入日志，再更新到buffer pool，达到了持久性要求。 隔离性是指事物内部的操作与其他事务是隔离的，并发执行的各个事务之间不能互相干扰。隔离性的探讨，主要分为两个方面：（1）写操作对写操作的影响：锁机制保证隔离性（2）写操作对读操作的影响：MVCC保证隔离性 一致性是指事务执行结束后，数据库的完整性约束没有被破坏，事务执行的前后都是合法的数据状态。 实现一致性的措施包括：（1）保证原子性、持久性和隔离性，如果这些特性无法保证，事务的一致性也无法保证。（2）数据库本身提供保障，例如不允许向整形列插入字符串值、字符串长度不能超过列的限制等（3）应用层面进行保障，录入转账操作之扣除转账者的月，而没有增加接收者的余额，无法保证状态一致。 隔离级别 隔离级别 脏读 不可重复读 幻读 读未提交 可能 可能 可能 读已提交 不可能 可能 可能 可重复读 不可能 不可能 可能 可串行化 不可能 不可能 不可能 123456（1）脏读当前事务（A）中可以读到其他事务（B）未提交的数据。（2）不可重复读在事务A中先后两次读取同一个数据，两次读取的结果不一样。（3）幻读在事务A中按照某个条件先后两次查询数据库，两次查询结果的条数不同。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://logan-liang.github.io/study/categories/MySQL/"}],"tags":[{"name":"MySQL事务","slug":"MySQL事务","permalink":"https://logan-liang.github.io/study/tags/MySQL%E4%BA%8B%E5%8A%A1/"}]},{"title":"同步锁、读写锁、WaitGroup","slug":"go-mutex-and-wg","date":"2021-04-26T06:55:30.000Z","updated":"2022-07-05T01:34:21.581Z","comments":true,"path":"2021/04/26/go-mutex-and-wg/","link":"","permalink":"https://logan-liang.github.io/study/2021/04/26/go-mutex-and-wg/","excerpt":"","text":"概述Go 语言中的sync包提供了两种锁类型：sync.Mutex和sync.RMWutex，前者是互斥锁，后者是读写锁。 同时，又提供了一种对主线程等待goroutine执行完毕的方法，sync.WaitGroup。 互斥锁互斥锁是传统的并发程序对共享资源进行访问控制的主要手段，在Go中，似乎更推崇由channel来实现资源共享和通信。它由标准库代码包sync中的Mutex结构体类型代表。只有两个公开的方法： 12Lock() &#x2F;&#x2F;获得锁UnLock() &#x2F;&#x2F;释放锁 Lock()：使用加锁后，不能再继续对其加锁（同一个goroutine中，即：同步调用），否则会panic。只有在unlock 之后才能再次lock。异步调用Lock()，是正当的锁竞争，当然不会有panic了。适用于读写不确定场景，即读写次数没有明显的却别，并且只允许只有一个读或者写的场景，所以该锁也叫做全局锁。 UnLock()：用于解锁，如果在使用Unlock前未加锁，就会引起一个运行错误。已经锁定的Mutex并不与特定的goroutine相关联，这样可以利用一个goroutine对其加锁，再利用其他goroutine对其解锁。 建议：同一个互斥锁的成对锁定和解锁操作放在同一层次的代码块中。 123456var lck sync.Mutexfunc foo() &#123; lck.Lock() defer lck.Unlock() &#x2F;&#x2F; ...&#125; lck.Lock() 会阻塞知道获取锁，然后利用defer语句在函数返回时自动释放锁。 读写锁读写锁是分别针对读操作和写操作进行锁定和解锁操作的互斥锁。在Go语言中，读写锁由结构体类型sync.RWMutex代表。 基本遵循原则： 写锁定情况下，对读写锁进行读锁定或者写锁定，都将阻塞；而且读锁与写锁之间是互斥的。 读锁定情况下，对读写锁进行锁定，将阻塞；加读锁时不会阻塞； 对未被写锁定的读写锁进行写解锁，会引发Panic； 对未被读锁定的读写锁进行读解锁的时候也会引发Panic； 写解锁在进行的同时会试图唤醒所有因进行读锁定而被阻塞的goroutine； 读解锁在进行的时候会试图唤醒一个因进行写锁定而被阻塞的goroutine； 与互斥锁类似，sync.RWMutex类型的零值就已经是立即可用的读写锁了。在此类型的方法集合中包含了两队方法。即： 1234func (*RWMutex) Lock &#x2F;&#x2F; 写锁定func (*RWMutex) Unlock &#x2F;&#x2F; 写解锁func (*RWMutex) RLock &#x2F;&#x2F; 读锁定func (*RWMutex) RUnlock &#x2F;&#x2F; 读解锁","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"锁的应用","slug":"锁的应用","permalink":"https://logan-liang.github.io/study/tags/%E9%94%81%E7%9A%84%E5%BA%94%E7%94%A8/"}]},{"title":"GraphQL 验证、执行、内省","slug":"graphQL-03","date":"2021-04-23T06:21:40.000Z","updated":"2022-07-05T01:34:15.891Z","comments":true,"path":"2021/04/23/graphQL-03/","link":"","permalink":"https://logan-liang.github.io/study/2021/04/23/graphQL-03/","excerpt":"","text":"验证通过使用类型系统，你可以预判一个查询是否有效。这让服务器和客户端可以在无效查询创建时就有效地通知开发者，而不用依赖运行时检查。 请看案例：点击查看 执行一个 GraphQL 查询在被验证后，GraphQL 服务器会将之执行，并返回与请求的结构相对应的结果，该结果通常会是 JSON 的格式。 GraphQL 不能脱离类型系统处理查询，让我们用一个类型系统的例子来说明一个查询的执行过程，在这一系列的文章中我们重复使用了这些类型，下文是其中的一部分： 12345678910111213141516171819type Query &#123; human(id: ID!): Human&#125;type Human &#123; name: String appearsIn: [Episode] starships: [Starship]&#125;enum Episode &#123; NEWHOPE EMPIRE JEDI&#125;type Starship &#123; name: String&#125; 调用 123456789&#123; human(id: 1002) &#123; name appearsIn starships &#123; name &#125; &#125;&#125; 内省我们有时候会需要去问 GraphQL Schema 它支持哪些查询。GraphQL 通过内省系统让我们可以做到这点！ 我们也可以通过查询 __schema 字段来向 GraphQL 询问哪些类型是可用的。一个查询的根类型总是有 __schema 这个字段。 1234567&#123; __schema &#123; types &#123; name &#125; &#125;&#125; 现在，来试试找到一个可以探索出有哪些可用查询的地方。当我们设计类型系统的时候，我们确定了一个所有查询开始的地方，来问问内省系统它是什么！ 1234567&#123; __schema &#123; queryType &#123; name &#125; &#125;&#125; 有时候也需要检验一个特定的类型。来看看 Droid 类型： 12345&#123; __type(name: &quot;Droid&quot;) &#123; name &#125;&#125; 如果我们想要更了解 Droid 呢？例如，它是一个接口还是一个对象？ 123456&#123; __type(name: &quot;Droid&quot;) &#123; name kind &#125;&#125; 对于一个对象来说，知道它有哪些字段是很有用的，所以来问问内省系统 Droid 有哪些字段： 12345678910111213&#123; __type(name: &quot;Droid&quot;) &#123; name fields &#123; name type &#123; name kind &#125; &#125; &#125;&#125; 我们可以看看它们的 ofType，就能知道它们是装什么东西的列表。 12345678910111213141516&#123; __type(name: &quot;Droid&quot;) &#123; name fields &#123; name type &#123; name kind ofType &#123; name kind &#125; &#125; &#125; &#125;&#125; 最后我们来看看内省系统特别适合用来开发工具的特性，我们来向内省系统请求文档！ { __type(name: “Droid”) { name description }}","categories":[{"name":"GraphQL","slug":"GraphQL","permalink":"https://logan-liang.github.io/study/categories/GraphQL/"}],"tags":[{"name":"GraphQL 入门","slug":"GraphQL-入门","permalink":"https://logan-liang.github.io/study/tags/GraphQL-%E5%85%A5%E9%97%A8/"}]},{"title":"GraphQL Schema和类型","slug":"graphQL-02","date":"2021-04-23T05:41:18.000Z","updated":"2022-07-05T01:34:08.962Z","comments":true,"path":"2021/04/23/graphQL-02/","link":"","permalink":"https://logan-liang.github.io/study/2021/04/23/graphQL-02/","excerpt":"","text":"系统类型（Type System）如果你之前见到过 GraphQL 查询，你就知道 GraphQL 查询语言基本上就是关于选择对象上的字段。因此，例如在下列查询中： 12345 hero &#123; name appearsIn &#125;&#125; 我们以一个特殊的对象 “root” 开始 选择其上的 hero 字段 对于 hero 返回的对象，我们选择 name 和 appearsIn 字段 一个关于我们所需要的数据的确切描述依然很有意义，我们能选择什么字段？服务器会返回哪种对象？这些对象下有哪些字段可用？这便是引入 schema 的原因。 每一个 GraphQL 服务都会定义一套类型，用以描述你可能从那个服务查询到的数据。每当查询到来，服务器就会根据 schema 验证并执行查询。 类型语言（Type Language）GraphQL 服务可以用任何语言编写，因为我们并不依赖于任何特定语言的句法句式（譬如 JavaScript）来与 GraphQL schema 沟通，我们定义了自己的简单语言，称之为 “GraphQL schema language” —— 它和 GraphQL 的查询语言很相似，让我们能够和 GraphQL schema 之间可以无语言差异地沟通。 对象类型和字段（Object Types and Fields）一个 GraphQL schema 中的最基本的组件是对象类型，它就表示你可以从服务上获取到什么类型的对象，以及这个对象有什么字段。使用 GraphQL schema language，我们可以这样表示它： 1234type Character &#123; name: String! appearsIn: [Episode!]!&#125; Character 是一个 GraphQL 对象类型，表示其是一个拥有一些字段的类型。你的 schema 中的大多数类型都会是对象类型。 name 和 appearsIn 是 Character 类型上的字段。这意味着在一个操作 Character 类型的 GraphQL 查询中的任何部分，都只能出现 name 和 appearsIn 字段。 String 是内置的标量类型之一 —— 标量类型是解析到单个标量对象的类型，无法在查询中对它进行次级选择。后面我们将细述标量类型。&amp; String! 表示这个字段是非空的，GraphQL 服务保证当你查询这个字段后总会给你返回一个值。在类型语言里面，我们用一个感叹号来表示这个特性。 [Episode!]! 表示一个 Episode 数组。因为它也是非空的，所以当你查询 appearsIn 字段的时候，你也总能得到一个数组（零个或者多个元素）。且由于 Episode! 也是非空的，你总是可以预期到数组中的每个项目都是一个 Episode 对象。 查询和变更类型（The Query and Mutation Types）你的 schema 中大部分的类型都是普通对象类型，但是一个 schema 内有两个特殊类型： 1234schema &#123; query: Query &#x2F;&#x2F;查询 mutation: Mutation &#x2F;&#x2F;变更&#125; 标量类型（Scalar Types）一个对象类型有自己的名字和字段，而某些时候，这些字段必然会解析到具体数据。这就是标量类型的来源：它们表示对应 GraphQL 查询的叶子节点。 GraphQL 自带一组默认标量类型： Int：有符号 32 位整数。 Float：有符号双精度浮点值。 String：UTF‐8 字符序列。 Boolean：true 或者 false。 ID：ID 标量类型表示一个唯一标识符，通常用以重新获取对象或者作为缓存中的键。ID 类型使用和 String 一样的方式序列化；然而将其定义为 ID 意味着并不需要人类可读型。 大部分的 GraphQL 服务实现中，都有自定义标量类型的方式。例如，我们可以定义一个 Date 类型： 1scalar Date 然后就取决于我们的实现中如何定义将其序列化、反序列化和验证。例如，你可以指定 Date 类型应该总是被序列化成整型时间戳，而客户端应该知道去要求任何 date 字段都是这个格式。 枚举类型（Enumeration Types）也称作枚举（enum），枚举类型是一种特殊的标量，它限制在一个特殊的可选值集合内。这让你能够： 验证这个类型的任何参数是可选值的的某一个 与类型系统沟通，一个字段总是一个有限值集合的其中一个值。 下面是一个用 GraphQL schema 语言表示的 enum 定义： 12345enum Episode &#123; NEWHOPE EMPIRE JEDI&#125; 这表示无论我们在 schema 的哪处使用了 Episode，都可以肯定它返回的是 NEWHOPE、EMPIRE 和 JEDI 之一。 列表和非空（Lists and Non-Null）对象类型、标量以及枚举是 GraphQL 中你唯一可以定义的类型种类。但是当你在 schema 的其他部分使用这些类型时，或者在你的查询变量声明处使用时，你可以给它们应用额外的类型修饰符来影响这些值的验证。我们先来看一个例子： 1234type Character &#123; name: String! appearsIn: [Episode]!&#125; 此处我们使用了一个 String 类型，并通过在类型名后面添加一个感叹号!将其标注为非空。这表示我们的服务器对于这个字段，总是会返回一个非空值，如果它结果得到了一个空值，那么事实上将会触发一个 GraphQL 执行错误，以让客户端知道发生了错误。 列表的运作方式也类似：在 GraphQL schema 语言中，我们通过将类型包在方括号（[ 和 ]）中的方式来标记列表。列表对于参数也是一样的运作方式，验证的步骤会要求对应值为数组。 非空和列表修饰符可以组合使用。例如你可以要求一个非空字符串的数组： 1myField: [String!] 这表示数组本身可以为空，但是其不能有任何空值成员。用 JSON 举例如下： 1234myField: null &#x2F;&#x2F; 有效myField: [] &#x2F;&#x2F; 有效myField: [&#39;a&#39;, &#39;b&#39;] &#x2F;&#x2F; 有效myField: [&#39;a&#39;, null, &#39;b&#39;] &#x2F;&#x2F; 错误 然后，我们来定义一个不可为空的字符串数组： 1myField: [String]! 这表示数组本身不能为空，但是其可以包含空值成员： 1234myField: null &#x2F;&#x2F; 错误myField: [] &#x2F;&#x2F; 有效myField: [&#39;a&#39;, &#39;b&#39;] &#x2F;&#x2F; 有效myField: [&#39;a&#39;, null, &#39;b&#39;] &#x2F;&#x2F; 有效 接口（Interfaces）一个接口是一个抽象类型，它包含某些字段，而对象类型必须包含这些字段，才能算实现了这个接口。 例如，你可以用一个 Character 接口用以表示《星球大战》三部曲中的任何角色： 123456interface Character &#123; id: ID! name: String! friends: [Character] appearsIn: [Episode]!&#125; 这意味着任何实现 Character 的类型都要具有这些字段，并有对应参数和返回类型。 例如，这里有一些可能实现了 Character 的类型： 12345678910111213141516type Human implements Character &#123; id: ID! name: String! friends: [Character] appearsIn: [Episode]! starships: [Starship] totalCredits: Int&#125;type Droid implements Character &#123; id: ID! name: String! friends: [Character] appearsIn: [Episode]! primaryFunction: String&#125; 可见这两个类型都具备 Character 接口的所有字段，但也引入了其他的字段 totalCredits、starships 和 primaryFunction，这都属于特定的类型的角色。 联合类型（Union Types）联合类型和接口十分相似，但是它并不指定类型之间的任何共同字段。 1union SearchResult &#x3D; Human | Droid | Starship 在我们的schema中，任何返回一个 SearchResult 类型的地方，都可能得到一个 Human、Droid 或者 Starship。注意，联合类型的成员需要是具体对象类型；你不能使用接口或者其他联合类型来创造一个联合类型。 输入类型（Input Types）目前为止，我们只讨论过将例如枚举和字符串等标量值作为参数传递给字段，但是你也能很容易地传递复杂对象。这在变更（mutation）中特别有用，因为有时候你需要传递一整个对象作为新建对象。在 GraphQL schema language 中，输入对象看上去和常规对象一模一样，除了关键字是 input 而不是 type： 1234input ReviewInput &#123; stars: Int! commentary: String&#125; 你可以像这样在变更（mutation）中使用输入对象类型： 1234567891011121314mutation CreateReviewForEpisode($ep: Episode!, $review: ReviewInput!) &#123; createReview(episode: $ep, review: $review) &#123; stars commentary &#125;&#125;&#123; &quot;ep&quot;: &quot;JEDI&quot;, &quot;review&quot;: &#123; &quot;stars&quot;: 5, &quot;commentary&quot;: &quot;This is a great movie!&quot; &#125;&#125;","categories":[{"name":"GraphQL","slug":"GraphQL","permalink":"https://logan-liang.github.io/study/categories/GraphQL/"}],"tags":[{"name":"GraphQL 入门","slug":"GraphQL-入门","permalink":"https://logan-liang.github.io/study/tags/GraphQL-%E5%85%A5%E9%97%A8/"}]},{"title":"GraphQL查询和变更","slug":"graphQL-01","date":"2021-04-23T03:30:28.000Z","updated":"2022-07-05T01:34:02.682Z","comments":true,"path":"2021/04/23/graphQL-01/","link":"","permalink":"https://logan-liang.github.io/study/2021/04/23/graphQL-01/","excerpt":"","text":"GraphQL 介绍GraphQL 是一个用于API的查询语言，是一个适用基于类型系统来执行查询的服务端运行时。GraphQL并没有和任何特定数据库或者存储引擎绑定，而是依靠你现有的代码和数据支撑。 一个GraphQL服务是通过定义类型和类型上的字段来创建的，然后每个类型上的每个字段提供解析函数。 一旦一个GraphQL服务运行起来，它就能接收GraphQL查询，并验证和执行。接收到的查询首先会被检查确保它只引用了已定义的类型和字段，然后运行指定的解析函数来生产结果。 查询和变更字段（Fields）简单而言，GraphQL是关于请求对象上的特定字段。我们以一个非常简单的查询以及其结果为例： 123456&#123; hero&#123; name id &#125;&#125; 输出 12345678&#123; &quot;data&quot;:&#123; &quot;hero&quot;:&#123; &quot;name&quot;:&quot;R2-D2&quot;, &quot;id&quot;:&quot;2001&quot; &#125; &#125;&#125; 你立即就能发现，查询和其结果拥有几乎一样的结构。这是GraphQL最重要的特性，因为这样一来，你就总是能得到你想要的数据，而服务器也准备的知道客户端请求的字段。 你也可以适用对象类型，你可以对这个对象的字段进行次级选择（sub-selection）。GraphQL查询能够遍历相关对象及其字段，使得客户端可以一次请求查询大量相关数据，而不像传统REST架构中那样需要多次往返查询。如下例子： 123456789&#123; hero &#123; name # 查询可以有备注！ friends &#123; name &#125; &#125;&#125; 输出 123456789101112131415161718&#123; &quot;data&quot;: &#123; &quot;hero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot;, &quot;friends&quot;: [ &#123; &quot;name&quot;: &quot;Luke Skywalker&quot; &#125;, &#123; &quot;name&quot;: &quot;Han Solo&quot; &#125;, &#123; &quot;name&quot;: &quot;Leia Organa&quot; &#125; ] &#125; &#125;&#125; 注意这个例子中，friends 返回了一个数组的项目，GraphQL 查询会同等看待单个项目或者一个列表的项目，然而我们可以通过 schema 所指示的内容来预测将会得到哪一种。 参数（Arguments）即使我们能做的仅仅是遍历对象及其字段，GraphQL就已经是一个非常有用的数据查询语言了。但是当你加入给字段传递参数的能力时，事情会变得更加有趣。 123456&#123; human(id: &quot;1000&quot;) &#123; name height &#125;&#125; 输出 12345678&#123; &quot;data&quot;: &#123; &quot;human&quot;: &#123; &quot;name&quot;: &quot;Luke Skywalker&quot;, &quot;height&quot;: 1.72 &#125; &#125;&#125; 在类似REST的系统中，你只能传递一组简单参数–请求中的query参数和URL段。但是在GraphQL中，每一个字段和潜逃对象都能有自己的一组参数，从而使得GraphQL可以完美替代多次API请求获取。甚至你也可以给标量（scalar）字段传递参数，用于实现服务端的一次转换，而不用每个客户端分别转换。 123456&#123; human(id: &quot;1000&quot;) &#123; name height(unit: FOOT) &#125;&#125; 输出 12345678&#123; &quot;data&quot;: &#123; &quot;human&quot;: &#123; &quot;name&quot;: &quot;Luke Skywalker&quot;, &quot;height&quot;: 5.6430448 &#125; &#125;&#125; 参数可以是多种不同的类型。上面例子中，我们使用了一个枚举类型，其代表了一个有限选项集合。GraphQL自带一套默认类型，但是GraphQL服务器可以声明一套自己的定制类型，只要能序列化成你的传输格式即可。 别名（Aliases）如果你眼睛够锐利，你可能已经发现，即便结果中的字段与查询中的字段能够匹配，但是因为他们并不包含参数，你就没法通过不同参数来查询相同字段。这便是为何需要别名–这可以让你重命名结果中的字段为任意你想到的名字。 12345678&#123; empireHero: hero(episode: EMPIRE) &#123; name &#125; jediHero: hero(episode: JEDI) &#123; name &#125;&#125; 输出 12345678910&#123; &quot;data&quot;: &#123; &quot;empireHero&quot;: &#123; &quot;name&quot;: &quot;Luke Skywalker&quot; &#125;, &quot;jediHero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot; &#125; &#125;&#125; 上例中，两个hero字段将会存在冲突，但是因为我们可以将其另取一个别名，我们也就可以在一次请求中得到两个结果。 片段（Fragments）假设我们的app有比较复杂的页面，将正反派主角及其友军分为两拨。你立马就能想到对应的查询会变得复杂。 这就是为何GraphQL包含了称作片段的可复用单元。片段使你能够组织一组字段，然后再需要它们的地方引入。如下： 12345678910111213141516&#123; leftComparison: hero(episode: EMPIRE) &#123; ...comparisonFields &#125; rightComparison: hero(episode: JEDI) &#123; ...comparisonFields &#125;&#125;fragment comparisonFields on Character &#123; name appearsIn friends &#123; name &#125;&#125; 输出 123456789101112131415161718192021222324252627282930313233343536373839404142434445&#123; &quot;data&quot;: &#123; &quot;leftComparison&quot;: &#123; &quot;name&quot;: &quot;Luke Skywalker&quot;, &quot;appearsIn&quot;: [ &quot;NEWHOPE&quot;, &quot;EMPIRE&quot;, &quot;JEDI&quot; ], &quot;friends&quot;: [ &#123; &quot;name&quot;: &quot;Han Solo&quot; &#125;, &#123; &quot;name&quot;: &quot;Leia Organa&quot; &#125;, &#123; &quot;name&quot;: &quot;C-3PO&quot; &#125;, &#123; &quot;name&quot;: &quot;R2-D2&quot; &#125; ] &#125;, &quot;rightComparison&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot;, &quot;appearsIn&quot;: [ &quot;NEWHOPE&quot;, &quot;EMPIRE&quot;, &quot;JEDI&quot; ], &quot;friends&quot;: [ &#123; &quot;name&quot;: &quot;Luke Skywalker&quot; &#125;, &#123; &quot;name&quot;: &quot;Han Solo&quot; &#125;, &#123; &quot;name&quot;: &quot;Leia Organa&quot; &#125; ] &#125; &#125;&#125; 你可以看到上面的查询如何漂亮地重复了字段。片段的概念经常用于将复杂的应用数据需求分割成小块，特别是你要将大量不同片段的UI组件组合成一个初始数据获取的时候。 在片段内使用变量片段可以访问查询或变更中声明的变量。 1234567891011121314151617181920query HeroComparison($first: Int &#x3D; 3) &#123; leftComparison: hero(episode: EMPIRE) &#123; ...comparisonFields &#125; rightComparison: hero(episode: JEDI) &#123; ...comparisonFields &#125;&#125;fragment comparisonFields on Character &#123; name friendsConnection(first: $first) &#123; totalCount edges &#123; node &#123; name &#125; &#125; &#125;&#125; 操作名称（Operation name）在这之前，我们都使用了简写句法，省略了query关键字和查询名称，但是生产中使用这些可以使我们代码减少歧义。 下面的示例包含了作为操作类型的关键字 query 以及操作名称： 12345678query HeroNameAndFriends &#123; hero &#123; name friends &#123; name &#125; &#125;&#125; 操作类型可以是query、mutaion和subscription，描述你打算做什么类型的操作。操作名称是你的操作的有意义和明确的名称。 变量（Variables）目前为止，我们将擦书卸载了查询字段内。但是在很多应用中，字段的参数可能是动态的。使用之前，我们得做三件事： 使用$variableName 替代查询中的静态值。 声明$variableName 为查询接收的变量之一。 将$variableName ：value通过传输专用（通常是json）的分离的变量字典中。 全部做完会像这个样子： 123456789# &#123; &quot;graphiql&quot;: true, &quot;variables&quot;: &#123; &quot;episode&quot;: JEDI &#125; &#125;query HeroNameAndFriends($episode: Episode) &#123; hero(episode: $episode) &#123; name friends &#123; name &#125; &#125;&#125; 变量定义（Variable definitions）变量定义看上去像是上述查询中的 ($episode: Episode)。其工作方式跟类型语言中函数的参数定义一样。它以列出所有变量，变量前缀必须为 $，后跟其类型，本例中为 Episode。 默认变量（Default variables）可以通过在查询中的类型定义后面附带默认值的方式，将默认值付给变量。 12345678query HeroNameAndFriends($episode: Episode &#x3D; &quot;JEDI&quot;) &#123; hero(episode: $episode) &#123; name friends &#123; name &#125; &#125;&#125; 指令（Directives）一个指令可以附着在字段或者片段包含的字段上，然后以任何服务端期待的方式来改变查询的执行。GraphQL 的核心规范包含两个指令，其必须被任何规范兼容的 GraphQL 服务器实现所支持： @include(if: Boolean) 仅在参数为 true 时，包含此字段。 @skip(if: Boolean) 如果参数为 true，跳过此字段。 指令在你不得不通过字符串操作来增减查询的字段时解救你。服务端实现也可以定义新的指令来添加新的特性。例子： 12345678query Hero($episode: Episode, $withFriends: Boolean!) &#123; hero(episode: $episode) &#123; name friends @include(if: $withFriends) &#123; name &#125; &#125;&#125; 变更 （Mutations）建一个约定来规范任何导致写入的操作都应该显式通过变更（mutation）来发送。就如同查询一样，如果任何变更字段返回一个对象类型，你也能请求其嵌套字段。获取一个对象变更后的新状态也是十分有用的。我们来看看一个变更例子： 123456mutation CreateReviewForEpisode($ep: Episode!, $review: ReviewInput!) &#123; createReview(episode: $ep, review: $review) &#123; stars commentary &#125;&#125; 参数： 1234567&#123; &quot;ep&quot;: &quot;JEDI&quot;, &quot;review&quot;: &#123; &quot;stars&quot;: 5, &quot;commentary&quot;: &quot;This is a great movie!&quot; &#125;&#125; 返回： 12345678&#123; &quot;data&quot;: &#123; &quot;createReview&quot;: &#123; &quot;stars&quot;: 5, &quot;commentary&quot;: &quot;This is a great movie!&quot; &#125; &#125;&#125; 变更多个字段（Multiple fields in mutations）一个变更也能包含多个字段，一组查询。查询和变更之间名称之外的一个重要区别是： 查询字段时，是并行执行，而变更字段时，是线性执行，一个接着一个。 这意味着如果我们一个请求中发送了两个 incrementCredits 变更，第一个保证在第二个之前执行，以确保我们不会出现竞态。 内联片段（Inline Fragments）如果你查询的字段返回的是接口或者联合类型，那么你可能需要使用内联片段来取出下层具体类型的数据： 12345678910111213141516query HeroForEpisode($ep: Episode!) &#123; hero(episode: $ep) &#123; name ... on Droid &#123; primaryFunction &#125; ... on Human &#123; height &#125; &#125;&#125;参数&#123; &quot;ep&quot;: &quot;JEDI&quot;&#125; 返回 12345678&#123; &quot;data&quot;: &#123; &quot;hero&quot;: &#123; &quot;name&quot;: &quot;R2-D2&quot;, &quot;primaryFunction&quot;: &quot;Astromech&quot; &#125; &#125;&#125; 元字段（Meta fields）某些情况下，你并不知道你将从 GraphQL 服务获得什么类型，这时候你就需要一些方法在客户端来决定如何处理这些数据。GraphQL 允许你在查询的任何位置请求 __typename，一个元字段，以获得那个位置的对象类型名称。 1234567891011121314&#123; search(text: &quot;an&quot;) &#123; __typename ... on Human &#123; name &#125; ... on Droid &#123; name &#125; ... on Starship &#123; name &#125; &#125;&#125; 输出 123456789101112131415161718&#123; &quot;data&quot;: &#123; &quot;search&quot;: [ &#123; &quot;__typename&quot;: &quot;Human&quot;, &quot;name&quot;: &quot;Han Solo&quot; &#125;, &#123; &quot;__typename&quot;: &quot;Human&quot;, &quot;name&quot;: &quot;Leia Organa&quot; &#125;, &#123; &quot;__typename&quot;: &quot;Starship&quot;, &quot;name&quot;: &quot;TIE Advanced x1&quot; &#125; ] &#125;&#125;","categories":[{"name":"GraphQL","slug":"GraphQL","permalink":"https://logan-liang.github.io/study/categories/GraphQL/"}],"tags":[{"name":"GraphQL 入门","slug":"GraphQL-入门","permalink":"https://logan-liang.github.io/study/tags/GraphQL-%E5%85%A5%E9%97%A8/"}]},{"title":"性能调试：分析并优化程序","slug":"performance-01","date":"2021-03-31T03:17:46.000Z","updated":"2022-07-05T01:33:52.748Z","comments":true,"path":"2021/03/31/performance-01/","link":"","permalink":"https://logan-liang.github.io/study/2021/03/31/performance-01/","excerpt":"","text":"时间和内存消耗可以用这个便捷脚本xtime来测量： 12#!&#x2F;bin&#x2F;sh&#x2F;usr&#x2F;bin&#x2F;time -f &#39;%Uu %Ss %er %MkB %C&#39; &quot;$@&quot; 用 go test 调试我们可以用 gotest 标准的 -cpuprofile 和 -memprofile 标志向指定文件写入 CPU 或 内存使用情况报告 1go test -x -v -cpuprofile&#x3D;prof.out -file x_test.go 用pprof 调试你可以在单机程序 progexec 中引入 runtime/pprof 包；这个包以 pprof 可视化工具需要的格式写入运行时报告数据。对于 CPU 性能分析来说你需要添加一些代码： 123456789101112var cpuprofile &#x3D; flag.String(&quot;cpuprofile&quot;, &quot;&quot;, &quot;write cpu profile to file&quot;)func main() &#123; flag.Parse() if *cpuprofile !&#x3D; &quot;&quot; &#123; f, err :&#x3D; os.Create(*cpuprofile) if err !&#x3D; nil &#123; log.Fatal(err) &#125; pprof.StartCPUProfile(f) defer pprof.StopCPUProfile() &#125; 代码定义了一个名为 cpuprofile 的 flag，调用 Go flag 库来解析命令行 flag，如果命令行设置了 cpuprofile flag，则开始 CPU 性能分析并把结果重定向到那个文件。（os.Create 用拿到的名字创建了用来写入分析数据的文件）。这个分析程序最后需要在程序退出之前调用 StopCPUProfile 来刷新挂起的写操作到文件中；我们用 defer 来保证这一切会在 main 返回时触发。 现在用这个 flag 运行程序：progexec -cpuprofile=progexec.prof 然后可以像这样用 gopprof 工具：gopprof progexec progexec.prof gopprof 程序是 Google pprofC++ 分析器的一个轻微变种；关于此工具更多的信息，参见https://github.com/gperftools/gperftools。 如果开启了 CPU 性能分析，Go 程序会以大约每秒 100 次的频率阻塞，并记录当前执行的 goroutine 栈上的程序计数器样本。 此工具一些有趣的命令： topN:用来展示分析结果中最开头的 N 份样本，例如：top5 它会展示在程序运行期间调用最频繁的 5 个函数 web 或 web 函数名:该命令生成一份 SVG 格式的分析数据图表，并在网络浏览器中打开它（还有一个 gv 命令可以生成 PostScript 格式的数据，并在 GhostView 中打开，这个命令需要安装 graphviz）。函数被表示成不同的矩形（被调用越多，矩形越大），箭头指示函数调用链 list 函数名 或 weblist 函数名:展示对应函数名的代码行列表，第 2 列表示当前行执行消耗的时间，这样就很好地指出了运行过程中消耗最大的代码如果发现函数 runtime.mallocgc（分配内存并执行周期性的垃圾回收）调用频繁，那么是应该进行内存分析的时候了。找出垃圾回收频繁执行的原因，和内存大量分配的根源 12345678910111213var memprofile &#x3D; flag.String(&quot;memprofile&quot;, &quot;&quot;, &quot;write memory profile to this file&quot;)...CallToFunctionWhichAllocatesLotsOfMemory()if *memprofile !&#x3D; &quot;&quot; &#123; f, err :&#x3D; os.Create(*memprofile) if err !&#x3D; nil &#123; log.Fatal(err) &#125; pprof.WriteHeapProfile(f) f.Close() return&#125; 用 -memprofile flag 运行这个程序：progexec -memprofile=progexec.mprof","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"性能调优","slug":"性能调优","permalink":"https://logan-liang.github.io/study/tags/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"}]},{"title":"反射包","slug":"package-02","date":"2021-03-26T08:43:00.000Z","updated":"2022-07-05T01:33:46.834Z","comments":true,"path":"2021/03/26/package-02/","link":"","permalink":"https://logan-liang.github.io/study/2021/03/26/package-02/","excerpt":"","text":"反射是用程序检查其所有的结构，尤其时类型的一种能力；这是元编程的一种形式。反射可以在运行时检查类型和变量，例如它的大小、方法和动态的调用这些方法。这对于没有源代码的包尤其有用。这是一个强大的工具，除非真的有必要，否则应当避免使用或小心使用。 变量的最基本信息就是类型和值：反射包的Type用来表示一个Go类型，反射包的Value为Go提供了反射接口。 实际上，反射时通过检查一个接口的值，变量首先被转换成空接口。接口的值包含一个type和value。 反射可以从接口反射到对象，也可以从对象反射回接口值。 什么时候该用到反射？ 为了降低多写代码造成的bug率，做更好的归约和抽象。 为了灵活、好用、方便，做动态解析、调用和处理。 为了代码好看、易读、提高开发效率，补足与动态语言之间的一些差别。 Go语言反射三大法则： 从interface&#123;&#125;变量可以反射出反射对象； 从反射对象可以获取interface&#123;&#125;变量； 要修改反射对象，其值必须可设置； Type和Value方法Type和Value拥有的同名方法 Method Type返回类型 Value返回类型 备注 Kind Kind Kind 返回指定对象的Kind类型 NumMethod int int 返回 struct 拥有的方法总数，包括 unexported 方法 MethodByName Method Value 根据方法名找方法 Method Method Value 返回第 i 个方法 NumField int int 返回 struct 所包含的 field 数量 Field StructField Value 取 struct 结构的第 n 个 field FieldByIndex StructField Value 嵌套的方式取 struct 的 field，比如 v.FieldByIndex ([] int {1,2}) 等价于 v.field (1).field (2) FieldByName StructField,bool Value 返回名称匹配 match 函数的 field FieldByNameFunc StructField,bool Value 返回名称匹配 match 函数的 field Type独有的方法 Method 备注 Align 分配内存时的内存对齐字节数 FieldAlign 作为 struct 的 field 时内存对齐字节数 Name type 名 string 类型 PkgPath 包路径， “encoding/base64”， 内置类型返回 empty string Size 该类型变量占用字节数 String type 的 string 表示方式 Implements 判断该类型是否实现了某个接口 AssignableTo 判断该类型能否赋值给某个类型 ConvertibleTo 判断该类型能否转换为另外一种类型 Comparable 判断该类型变量是否可以比较 ChanDir 返回 channel 的方向 recv/send/double IsVariadic 判断函数是否接受可变参数 Elem 取该类型的元素 In 函数第 n 个入参 Out 函数第 n 个出参 NumIn 函数的入参数个数 NumOut 函数的出参个数 Key 返回 map 结构的 key 类型 Type Len 返回 array 的长度 Value独有的方法 Method 备注 Addr v 的指针，前提时 CanAddr () 返回 true Bool 取值，布尔类型 Bytes 取值，字节流 Call 调用函数 CallSlice 调用具有可变参的函数 CanAddr 判断能否取址 CanInterface 判断 Interface 方法能否使用 CanSet 判断 v 的值能否改变 Cap 判断容量 Array/Chan/Slice Close 关闭 Chan Complex 取值，复数 Convert 返回将 v 转换位 type t 的结果 Elem 返回 interface 包含或者 Ptr 指针的实际值 Float 取值，浮点型 Index 索引操作 Array/Slice/String Int 取值，整型 Interface 将当前 value 以 interface {} 形式返回 IsNil 判断是否为 nil，chan, func, interface, map, pointer, or slice value IsValid 是否是可操作的 Value，返回 false 表示为 zero Value Len 适用于 Array, Chan, Map, Slice, or String MapIndex 对 map 类型按 key 取值 MapKeys map 类型的所有 key 的列表 OverflowComplex 溢出判断 OverflowFloat 溢出判断 OverflowInt 溢出判断 OverflowUint 溢出判断 Pointer 返回 uintptr 适用于 slice Recv chan 接收 Send chan 发送 Set 将 x 赋值给 v，类型要匹配 SetBool Bool 赋值，需要先判断 CanSet () 为 true SetBytes Bytes 赋值 SetCap slice 调整切片容量 SetMapIndex map 索引赋值 SetUint Unit 赋值 SetPointer unsafe.Pointer 赋值 SetString String 赋值 Slice return v [i:j] 适用于 Array/Slict/String String return value 的 string 表示方法 TryRecv chan 非阻塞接收 TrySend chan 非阻塞发送 Type 返回 value 的 Type UnsafeAddr 返回指向 value 的 data 的指针","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"内部包","slug":"内部包","permalink":"https://logan-liang.github.io/study/tags/%E5%86%85%E9%83%A8%E5%8C%85/"}]},{"title":"内部包","slug":"package-01","date":"2021-03-25T01:46:42.000Z","updated":"2022-07-05T01:33:40.366Z","comments":true,"path":"2021/03/25/package-01/","link":"","permalink":"https://logan-liang.github.io/study/2021/03/25/package-01/","excerpt":"","text":"unsafe：包含了一些打破 Go 语言“类型安全”的命令，一般的程序中不会被使用，可用在 C/C++ 程序的调用中 syscall-os-os/exec： os: 提供给我们一个平台无关性的操作系统功能接口，采用类Unix设计，隐藏了不同操作系统间差异，让不同的文件系统和操作系统对象表现一致。 os/exec: 提供我们运行外部操作系统命令和程序的方式。 syscall: 底层的外部包，提供了操作系统底层调用的基本接口。 archive/tar 和 /zip-compress：压缩(解压缩)文件功能。 fmt-io-bufio-path/filepath-flag: fmt: 提供了格式化输入输出功能。 io: 提供了基本输入输出功能，大多数是围绕系统功能的封装。 bufio: 缓冲输入输出功能的封装。 path/filepath: 用来操作在当前系统中的目标文件名路径。 flag: 对命令行参数的操作。 strings-strconv-unicode-regexp-bytes: strings: 提供对字符串的操作。 strconv: 提供将字符串转换为基础类型的功能。 unicode: 为 unicode 型的字符串提供特殊的功能。 regexp: 正则表达式功能。 bytes: 提供对字符型分片的操作。 index/suffixarray: 子字符串快速查询。 math-math/cmath-math/big-math/rand-sort: math: 基本的数学函数。 math/cmath: 对复数的操作。 math/rand: 伪随机数生成。 sort: 为数组排序和自定义集合。 math/big: 大数的实现和计算。 container-/list-ring-heap: 实现对集合的操作。 list: 双链表。 ring: 环形链表。 time-log: time: 日期和时间的基本操作。 log: 记录程序运行时产生的日志,我们将在后面的章节使用它。 encoding/json-encoding/xml-text/template: encoding/json: 读取并解码和写入并编码 JSON 数据。 encoding/xml:简单的 XML1.0 解析器,有关 JSON 和 XML 的实例请查阅第 12.9/10 章节。 text/template:生成像 HTML 一样的数据与文本混合的数据驱动模板（参见第 15.7 节）。 net-net/http-html: net: 网络数据的基本操作。 http: 提供了一个可扩展的 HTTP 服务器和基础客户端，解析 HTTP 请求和回复。 html: HTML5 解析器。 runtime: Go 程序运行时的交互操作，例如垃圾回收和协程创建。 reflect: 实现通过程序运行时反射，让程序操作任意类型的变量。","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"内部包","slug":"内部包","permalink":"https://logan-liang.github.io/study/tags/%E5%86%85%E9%83%A8%E5%8C%85/"}]},{"title":"数组与切片","slug":"four-arr-slice-01","date":"2021-03-24T07:54:30.000Z","updated":"2022-07-05T01:32:52.628Z","comments":true,"path":"2021/03/24/four-arr-slice-01/","link":"","permalink":"https://logan-liang.github.io/study/2021/03/24/four-arr-slice-01/","excerpt":"","text":"数组声明与初始化数组时具有相同唯一类型的一组已编号且长度固定的数据项序列。 数组元素可以通过索引（位置）来读取或修改，索引从0开始，第一个元素索引为0，第二个索引为1，以此类推。数组长度最大为2GB。 声明格式为： 1var arr1 [5]int Go语言中的数组是一种值类型，可以通过new()来创建。那么使用这种方式和正常声明有什么区别呢？ 这样的结果就是当把一个数组赋值给另一个时，需要再做一次数组内存的拷贝操作。 数组常量如果数组值已经提前知道了，那么可以通过数组常量的方法来初始化数组，而不用一次使用[]=方法。 第一种变化： 1var arr&#x3D;[5]int&#123;1,2,3,4,5&#125; 注意 [5]int 可以从左边起开始忽略：[10]int &#123;1, 2, 3&#125; :这是一个有 10 个元素的数组，除了前三个元素外其他元素都为 0。 第二种变化： 1var arrLazy &#x3D; [...]int&#123;5, 6, 7, 8, 22&#125; ... 可同样可以忽略，从技术上说它们其实变化成了切片。 第三种变化： 1var arrKeyValue &#x3D; [5]string&#123;3: &quot;Chris&quot;, 4: &quot;Ron&quot;&#125; 只有索引 3 和 4 被赋予实际的值，其他元素都被设置为空的字符串 将数组传递给函数把一个大数组传递给函数会消耗很多内存。有两种方法可以避免这种现象： 传递数组的指针 使用数组的切片 切片切片（slice）是对数组一个连续片段的引用，所以切片是一个引用类型。这个片段可以是整个数组，或者时由起始和终止索引标识的一些项的子集。 切片是可以索引的，并且可以由len()函数获取长度。 切片时一个长度可变的数组。 切片提供了计算容量的函数cap()，可以测量切片最长可以达到多少。 多个切片如果表示同一个数组的片段，它们可以共享数据；因此一个切片和相关数组的其它切片都是共享存储的，相反，不同的数组总是导标不同的存储。 优点因切片时引用，所以它们不需要使用额外的内存并且比使用数组更有效率，所以在go代码中切片比数组更常用。 创建切片12slice:&#x3D;make([]int,len,cap)slice:&#x3D;new([]int) new()和make()的区别 new(T) 为每个新的类型T分配一片内存，初始化为0并且返回类型为*T的内存地址，她适用于值类型数组和结构体，相当于&amp;T&#123;&#125; make(T) 返回一个类型为T的初始值，他只适用于3种内建的引用类型：切片、map和channel。 切片重组改变切片长度的过程称之为切片重组 reslicing 示例： 1slice1 &#x3D; slice1[0:end] 切片的复制与追加 追加 append(s[]T,x …T):将0个或多个具有相同类型s的元素追加到切片后面并且返回新的切片；追加的元素必须和原切片的元素同类型。如果s的容量不足以存储新增元素，append会分配新的切片来保证已有切片元素和新增元素的存储。因此，返回的切片可能已经指向一个不同的相关数组了。append方法总是返回成功，除非系统内存耗尽。 复制 copy(dst,src []T) int: copy方法将类型为T的切片从原地址src拷贝到目标地址dst，覆盖dst的相关元素，并且返回拷贝的元素个数。原地址和目标地址可能会有重叠。拷贝个数时src和dst的长度最小值。如果src时字符串那么元素类型就是byte。如果你还想继续使用src，在拷贝结束后执行src=dst。 map切片123456789func main() &#123; &#x2F;&#x2F; Version A: items :&#x3D; make([]map[int]int, 5) for i:&#x3D; range items &#123; items[i] &#x3D; make(map[int]int, 1) items[i][1] &#x3D; 2 &#125; fmt.Printf(&quot;Version A: Value of items: %v\\n&quot;, items)&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"数组与切片","slug":"数组与切片","permalink":"https://logan-liang.github.io/study/tags/%E6%95%B0%E7%BB%84%E4%B8%8E%E5%88%87%E7%89%87/"}]},{"title":"闭包","slug":"three-func-02","date":"2021-03-24T06:32:15.000Z","updated":"2022-07-05T01:33:04.753Z","comments":true,"path":"2021/03/24/three-func-02/","link":"","permalink":"https://logan-liang.github.io/study/2021/03/24/three-func-02/","excerpt":"","text":"当我们不希望给函数起名字的时候，可以使用匿名函数，例如：func(x, y int) int &#123; return x + y &#125;。 这样的一个函数不能够独立存在，但可以被赋值某个变量，即保存函数的地址到变量中。 12fplus :&#x3D; func(x, y int) int &#123; return x + y &#125; 然后通过变量名对函数进行调用：fplus(3,4) 匿名函数像所有函数一样可以接受或不接受参数。下面的例子展示了如何传递参数到匿名函数中： 1234func (u string) &#123; fmt.Println(u) …&#125;(v) 思考：下列方法输出的内容是什么？ 12345678910111213package mainimport &quot;fmt&quot;func f() (ret int) &#123; defer func() &#123; ret++ &#125;() return 1&#125;func main() &#123; fmt.Println(f())&#125; 变量ret的值为2，因为ret++是在执行return 1语句后发生的。 这可用于在返回语句之后修改返回的error时使用。 defer语句和匿名函数关键字 defer 经常配合匿名函数使用，它可以用于改变函数的命名返回值。 匿名函数还可以配合go关键字来作为goroutine使用。 匿名函数同样称之为闭包。 应用闭包：将函数作为返回值语法： 12func Add2() (func(b int) int)func Adder(a int) (func(b int) int) 函数add2不接受任何参数，但函数Adder接受一个int类型的整数作为参数。 例子： 1234567891011121314151617181920func main() &#123; &#x2F;&#x2F; make an Add2 function, give it a name p2, and call it: p2 :&#x3D; Add2() fmt.Printf(&quot;Call Add2 for 3 gives: %v\\n&quot;, p2(3)) &#x2F;&#x2F; make a special Adder function, a gets value 2: TwoAdder :&#x3D; Adder(2) fmt.Printf(&quot;The result is: %v\\n&quot;, TwoAdder(3))&#125;func Add2() func(b int) int &#123; return func(b int) int &#123; return b + 2 &#125;&#125;func Adder(a int) func(b int) int &#123; return func(b int) int &#123; return a + b &#125;&#125; 输出： 12Call Add2 for 3 gives: 5The result is: 5","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"函数","slug":"函数","permalink":"https://logan-liang.github.io/study/tags/%E5%87%BD%E6%95%B0/"}]},{"title":"函数参数与返回值","slug":"three-func-01","date":"2021-03-24T05:56:16.000Z","updated":"2022-07-05T01:32:58.369Z","comments":true,"path":"2021/03/24/three-func-01/","link":"","permalink":"https://logan-liang.github.io/study/2021/03/24/three-func-01/","excerpt":"","text":"函数能够接收参数供自己使用，也可以返回零个或多个值。 我们通过return关键字返回一组值。事实上，任何一个有返回值的函数都必须以return或panic结尾。 在函数块里面，return之后的语句都不会执行。如果一个函数需要返回值，那么这个函数里面的每一个代码分支都要return语句。 按值传递（call by value）按引用传递（call by reference）在任何情况下，传递指针（一个32位或者64位的值）的消耗都比传递副本来的少。 在函数调用时，像切片、字典、接口、通道这样的引用类型都是默认使用引用传递。 有些函数只是完成一个任务，并没有返回值。但是绝大部分的函数还是带有返回值的。 如果一个函数需要返回四到五个值，我们可以传递一个切片给函数或者传递一个结构体。因为传递一个指针允许直接修改变量的值，消耗更少。 1234567(A) func DoSomething(a *A) &#123; b &#x3D; a &#125;(B) func DoSomething(a A) &#123; b &#x3D; &amp;a &#125; 命名的返回值（name return variables）123456func getX2AndX3_2(input int) (x2 int, x3 int) &#123; x2 &#x3D; 2 * input x3 &#x3D; 3 * input &#x2F;&#x2F; return x2, x3 return&#125; 尽量使用命名返回值：会使代码更清晰、更简短，同时更加容易读懂。 改变外部变量（outside variable）传递指针给函数不但可以节省内存，而且赋予了函数直接修改外部变量的能力，所以被修改的变量不再需要使用return返回。 1234567891011&#x2F;&#x2F; this function changes reply:func Multiply(a, b int, reply *int) &#123; *reply &#x3D; a * b&#125;func main() &#123; n :&#x3D; 0 reply :&#x3D; &amp;n Multiply(10, 5, reply) fmt.Println(&quot;Multiply:&quot;, *reply) &#x2F;&#x2F; Multiply: 50&#125; 这仅仅是个指导性的例子，当需要在函数内改变一个占用内存比较大的变量时，性能优势就更加明显了。然而，如果不小心使用的话，传递一个指针很容易引发一些不确定的事，所以，我们要十分小心那些可以改变外部变量的函数，在必要时，需要添加注释以便其他人能够更加清楚的知道函数里面到底发生了什么","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"函数","slug":"函数","permalink":"https://logan-liang.github.io/study/tags/%E5%87%BD%E6%95%B0/"}]},{"title":"for结构","slug":"two-struct-03","date":"2021-03-24T02:16:54.000Z","updated":"2022-07-05T01:33:34.203Z","comments":true,"path":"2021/03/24/two-struct-03/","link":"","permalink":"https://logan-liang.github.io/study/2021/03/24/two-struct-03/","excerpt":"","text":"Go语言中您只有for结构可以使用。不要小看它，这个for结构比其它语言中的更为灵活。 基于计数器的迭代1for 初始化语句；条件语句；修饰语句&#123;&#125; 示例1 123for i:&#x3D;0;i&lt;5;i++&#123; &#x2F;&#x2F;do something&#125; 示例2 1for i,j:&#x3D;0,N;i&lt;j;i,j&#x3D;i+1,j-1&#123;&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"控制结构","slug":"控制结构","permalink":"https://logan-liang.github.io/study/tags/%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84/"}]},{"title":"switch语句","slug":"two-struct-02","date":"2021-03-24T02:05:16.000Z","updated":"2022-07-05T01:33:26.603Z","comments":true,"path":"2021/03/24/two-struct-02/","link":"","permalink":"https://logan-liang.github.io/study/2021/03/24/two-struct-02/","excerpt":"","text":"Go语言中的switch结构使用上更加灵活。它接受任意形式的表达式： 12345678switch var1&#123; case val1: &#x2F;&#x2F;do something case val2: &#x2F;&#x2F;do something default: &#x2F;&#x2F;do something &#125; 变量val1可以是任何类型，而val1和val2则可以时同类型的任意值。类型不被局限于常量和整数，但必须是相同的类型；或者最终结果为相同类型的表达式。 每一个case分支都是唯一的，从上至下逐一测试，直到匹配为止。 一旦成功地匹配到某个分支，在执行完相应代码后就会退出整个switch代码块，也就是说您不需要特别地使用break语句来表示结束。","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"控制结构","slug":"控制结构","permalink":"https://logan-liang.github.io/study/tags/%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84/"}]},{"title":"if-else结构","slug":"two-struct-01","date":"2021-03-24T01:42:09.000Z","updated":"2022-07-05T01:33:20.891Z","comments":true,"path":"2021/03/24/two-struct-01/","link":"","permalink":"https://logan-liang.github.io/study/2021/03/24/two-struct-01/","excerpt":"","text":"if是用于测试某个条件的语句，如果条件成立，则会执行if后由大括号扩起来的代码块，否则就忽略该代码块继续执行后续的代码。 123if condition&#123; &#x2F;&#x2F;do something&#125; 如果存在第二个分支，则可以在上面代码的基础上添加else关键字以及另一代码块，这个代码块中的代码只有条件不满足时才会执行。if和else后的两个代码块是相互独立的分支，只可能执行其中一个。 12345if condition&#123; &#x2F;&#x2F;do something&#125;else&#123; &#x2F;&#x2F;do something&#125; 如果存在第三个分支，则可以使用下面这种三个独立分支的形式： 1234567if condition1&#123; &#x2F;&#x2F;do something&#125;else if condition2&#123; &#x2F;&#x2F;do something else&#125;else&#123; &#x2F;&#x2F; catch-call or default&#125; 还可以这样定义 123if val:&#x3D;func(data);val&gt;max&#123; &#x2F;&#x2F;do something&#125;","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"控制结构","slug":"控制结构","permalink":"https://logan-liang.github.io/study/tags/%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84/"}]},{"title":"指针","slug":"two-basic-02","date":"2021-03-24T01:05:54.000Z","updated":"2022-07-05T01:33:11.209Z","comments":true,"path":"2021/03/24/two-basic-02/","link":"","permalink":"https://logan-liang.github.io/study/2021/03/24/two-basic-02/","excerpt":"","text":"Go语言位程序员提供了控制数据结构的指针的能力；但是，你不能进行指针运算。通过给予程序员基本内存布局，Go语言允许你控制特定集合的数据结构、分配的数量以及内存访问模式，这些对构建运行良好的系统是非常重要的：指针对于性能的影响是不言而喻的，而如果你想要做的是系统编程、操作系统或者网络应用，指针更是不可或缺的一部分。 程序在内存中存储它的值，每个内存块（或字）有一个地址，通常用十六进制数表示，如0x6b0820。 Go语言的取地址符是&amp;，放到一个变量前使用就会返回相应变量的内存地址。*操作符作为右值时，意义是取指针的值，作为左值时，也就是放在赋值操作符的左边时，表示a指针指向的变量。其实归纳起来，*操作符的根本意义就是操作指针指向的变量。当操作在右值时，就是取指向变量的值，当操作在左值时，就是将值设置给指向的变量。 一个指针变量可以指向任何一个值的内存地址 它指向那个值的内存地址，在32位机器上占用4个字节，在64位机器上占用8个字节，并且与它所指向的值的大小无关。当然，可以声明指针指向任何类型的值来表明它的原始性或结构性。 当一个指针被定义后没有分配到任何变量时，它的值为nil。 一个指针变量通常缩写为ptr。 指针的一个高级应用是你可以传递一个变量的引用，这样不会传递变量的拷贝。指针传递是很廉价的，只占用4个或8个字节。当程序在工作中需要占用大量的内存，或很多变量，或者两者都有，使用指针会减少内存占用和提高效率。被指向的变量也保存在内存中，直到没有任何指针指向它们，所以从它们被创建开始就具有相互独立的生命周期。 对一个空指针的反向引用是不合法的，并且会使程序崩溃。","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"基本结构和基本数据类型","slug":"基本结构和基本数据类型","permalink":"https://logan-liang.github.io/study/tags/%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"}]},{"title":"strings和strconv包","slug":"two-basic-01","date":"2021-03-08T10:51:38.000Z","updated":"2022-07-05T01:32:47.116Z","comments":true,"path":"2021/03/08/two-basic-01/","link":"","permalink":"https://logan-liang.github.io/study/2021/03/08/two-basic-01/","excerpt":"","text":"作为一种基本数据结构，每种语言都有一些对于字符串的预定义函数。Go中使用strings包来完成对字符串的主要操作。 前缀和后缀HasPrefix判断字符串s是否以prefix开头： 1strings.HasPrefix(s,prefix string) bool HasSuffix判断字符串s是否以suffix结尾： 1strings.HasSuffix(s,prefix string) bool 字符串包含关系Contains 判断字符串s是否包含substr： 1strings.Contains(s,substr string) bool 判断子字符串或字符在父字符中出现的位置（索引）Index 返回字符串 str 在字符串 s 中的索引（str 的第一个字符的索引），-1 表示字符串 s 不包含字符串 str： 1strings.Index(s,str string) int LastIndex返回字符串str在字符串s中最后出现位置的索引（str的第一个字符的索引），-1代表字符串s不包含字符串str： 1strings.LastIndex(s,str string) int 如果需要查询非ASCII编码的字符在父字符串中的位置，建议使用以下函数来对字符进行定位： 1strings.IndexRune(s string,r rune) int 字符串替换Replace 用于将字符串 str 中的前 n 个字符串 old 替换为字符串 new，并返回一个新的字符串，如果 n = -1 则替换所有字符串 old 为字符串 new： 1strings.Replace(str,old,new,n) string 统计字符串出现次数Count用于计算字符串str在字符串s中出现的非重叠次数： 1strings.Count(s,str string) int 重复字符串Repeat 用于重复count次字符串s并返回一个新的字符串： 1strings.Repeat(s,count int) string 修改字符串大小写ToLower将字符串中的Unicode字符全部转换位相应的小写字符： 1strings.ToLower(s) string ToUpper将字符串中的Unicode字符全部转换位相应的大写字符： 1strings.ToUpper(s) string 修剪字符串你可以使用 strings.TrimSpace(s) 来剔除字符串开头和结尾的空白符号；如果你想要剔除指定字符，则可以使用 strings.Trim(s, &quot;cut&quot;) 来将开头和结尾的 cut 去除掉。该函数的第二个参数可以包含任何字符，如果你只想剔除开头或者结尾的字符串，则可以使用 TrimLeft 或者 TrimRight 来实现。 分割字符串strings.Fields(s) 将会利用 1 个或多个空白符号来作为动态长度的分隔符将字符串分割成若干小块，并返回一个 slice，如果字符串只包含空白符号，则返回一个长度为 0 的 slice。 strings.Split(s, sep) 用于自定义分割符号来对指定字符串进行分割，同样返回 slice。 拼接字符串Join 用于将元素类型为 string 的 slice 使用分割符号来拼接组成一个字符串： 1strings.Join(sl []string, sep string) string 从字符串中读取内容函数 strings.NewReader(str) 用于生成一个 Reader 并读取字符串中的内容，然后返回指向该 Reader 的指针，从其它类型读取内容的函数还有： Read() 从 []byte 中读取内容。 ReadByte() 和 ReadRune() 从字符串中读取下一个 byte 或者 rune。 字符串以其它类型转换与字符串相关的类型转换都是通过strconv包实现的。 获取程序运行的操作系统平台下int类型所占的位数1strconv.IntSize() 返回数字i所表示的字符串类型的十进制数1strconv.Itoa(i int) string 将 64 位浮点型的数字转换为字符串1strconv.FormatFloat(f float64, fmt byte, prec int, bitSize int) string 将字符串转换为 int 型1strconv.Atoi(s string) (i int, err error) 将字符串转换为 float64 型1strconv.ParseFloat(s string, bitSize int) (f float64, err error)","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"基本结构和基本数据类型","slug":"基本结构和基本数据类型","permalink":"https://logan-liang.github.io/study/tags/%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"}]},{"title":"字符串","slug":"one-basic-06","date":"2021-03-08T10:14:59.000Z","updated":"2022-07-05T01:32:39.305Z","comments":true,"path":"2021/03/08/one-basic-06/","link":"","permalink":"https://logan-liang.github.io/study/2021/03/08/one-basic-06/","excerpt":"","text":"简述字符串是UTF-8字符的一个序列（当字符为 ASCII 码时则占用 1 个字节，其它字符根据需要占用 2-4 个字节）。UTF-8是被广泛使用的编码格式，是文本文件的标准编码，其它包括XML和JSON在内，也都使用该编码。由于该编码对占用字节长度的不定性，Go中的字符串里的字符也可能根据需要占用1至4字节。Go这样做的好处是不仅减少了内存和硬盘空间占用，同时也不用像其它语言那样需要对使用UTF-8字符集的文本进行编码和解码。 字符串是一种值类型，且值不可变，即创建某个文本后你无法再次修改这个文本的内容；更深入的讲，字符串是字节的定长数组。 Go支持以下2种形式的字面值： 解释字符串：该类字符串使用双引号扩起来，其中的相关的转义字符将被替换，这些转义字符包括： \\n：换行符 \\r：回车符 \\t：tab 键 \\u：Unicode 字符 \\\\：反斜杠自身 非解释字符串：该类字符串使用反引号扩起来，支持换行，例如： 1&#96;This is a raw string \\n&#96; 中的 &#96;\\n\\&#96; 会被原样输出。 Go中的字符串是根据长度限定，而非特殊字符\\0。 string类型的零值位长度为零的字符串，即空字符串&quot;&quot;。 你可以通过函数 len() 来获取字符串所占的字节长度，例如：len(str)。 字符串的内容（纯字节）可以通过标准索引法来获取，在中括号[]内写入索引，索引从0开始计数： 字符串str的第一个字节：str[0] 第i个字节：str[i-1] 最后1个字节：str[len(str)-1] 需要注意的是，这种转换方案只针对纯ASCII码的字符串有效。 字符串拼接符 +两个字符串s1和s2可以通过 s:=s1+s2拼接在一起。 s2追加在s1尾部并生成一个新的字符串s。 在循环中使用+拼接字符并不是最高效的做法，更好的办法是使用函数strings.Join(),有没有更好的办法了？有！使用字节缓冲（bytes.Buffer）拼接更加给力。","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"基本结构和基本数据类型","slug":"基本结构和基本数据类型","permalink":"https://logan-liang.github.io/study/tags/%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"}]},{"title":"基本类型和运算符","slug":"one-basic-05","date":"2021-03-08T09:46:26.000Z","updated":"2022-07-05T01:32:31.987Z","comments":true,"path":"2021/03/08/one-basic-05/","link":"","permalink":"https://logan-liang.github.io/study/2021/03/08/one-basic-05/","excerpt":"","text":"简述我们将在这个部分讲解有关布尔型、数字型和字符型的相关知识。 表达式是一种特定的类型的值，它可以由其它的值以及运算符组合而成。每个类型都定义了可以和自己结合的运算符集合，如果你使用了不在这个集合中的运算符，则会在编译时获得编译错误。 一元运算符只可以用于一个值的操作（作为后缀），而二元运算符则可以和两个值或者操作数结合（作为中缀）。 只有两个类型相同的值才可以和二元运算符结合，另外要注意的是，Go是强类型语言，因此不会进行隐式转换，任何不同类型之间的转换都必须显示说明，表达式的解析顺序是从左至右的。 布尔类型 bool一个简单的例子：var b bool =true。 布尔型的值只可以是常量true或者false。 两个类型相同的值可以用相等==或者不等!=运算符进行比较并获得一个布尔型的值。 当相等运算符两边的值是完全相同的值的时候会返回true，否则返回false，并且只有在两个的值的类型相同的情况下才可以使用。 示例： 123var aVar &#x3D; 10aVar &#x3D;&#x3D;5 &#x2F;&#x2F;falseaVar &#x3D;&#x3D;10 &#x2F;&#x2F;true Go语言对于值之间的比较有非常严格的限制，只有两个类型相同的值才可以进行比较。 对于布尔值的好的命名能够很好地提升代码的可读性，例如以is或者Is开头。 数字类型整型 int 和浮点型 floatGo语言支持整型和浮点型数字，并且原生支持复数。 Go也有基本架构的类型，例如：int、unit和unitptr。 这些类型的长度都是根据运行程序所在的操作系统类型所决定的： int和unit在32位操作系统上，它们均使用32位（4个字节），在64位操作系统上，它们均使用64位（8个字节）。 uintptr的长度被设定位足够存放一个指针即可。 Go语言中没有float类型。（只有float32和float64）没有double类型。 与操作系统架构无关的类型都有固定的大小，并在类型的名称中就可以看出来： 整数： int8（-128 -&gt; 127） int16（-32768 -&gt; 32767） int32（-2,147,483,648 -&gt; 2,147,483,647） int64（-9,223,372,036,854,775,808 -&gt; 9,223,372,036,854,775,807） 无符号整数： uint8（0 -&gt; 255） uint16（0 -&gt; 65,535） uint32（0 -&gt; 4,294,967,295） uint64（0 -&gt; 18,446,744,073,709,551,615） 浮点型（IEEE-754 标准）： float32（+- 1e-45 -&gt; +- 3.4 * 1e38） float64（+- 5 * 1e-324 -&gt; 107 * 1e308）","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"基本结构和基本数据类型","slug":"基本结构和基本数据类型","permalink":"https://logan-liang.github.io/study/tags/%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"}]},{"title":"变量","slug":"one-basic-04","date":"2021-03-07T11:23:07.000Z","updated":"2022-07-05T01:32:23.170Z","comments":true,"path":"2021/03/07/one-basic-04/","link":"","permalink":"https://logan-liang.github.io/study/2021/03/07/one-basic-04/","excerpt":"","text":"简介声明变量的一般形式是使用var关键字：var identifier type。 需要注意的是，Go和许多编程语言不同，它在声明变量时将变量的类型放在变量的名称之后。Go为什么要选择这么做呢？ 首先，它是为了避免像C语言中那样含糊不清的声明形式，例如：int * a,b。而在Go语言中，则可以很轻松地将它们都声明为指针类型： var a,b *int其次，这种语法能够按照从左至右的顺序阅读，使得代码更加容易理解。 示例： 123var a intvar b bollvar str string 你也可以改写成这种形式： 12345var( a int b bool c string) 这种因式分解关键字的写法一般用于声明全局变量。 当一个变量被声明之后，系统自动赋予它该类型的零值：int 为 0，float 为 0.0，bool 为 false，string 为空字符串，指针为 nil。记住，所有的内存在 Go 中都是经过初始化的。 变量的命名规则遵循骆驼命名法，即首个单词小写，每个新单词的首字母大写，例如：numShips 和 startDate。 但如果你的全局变量希望能够被外部包所使用，则需要将首个单词的首字母也大写。 一个变量（常量、类型和函数）在程序中都有一定的作用范围，称之为作用域。如果一个变量在函数体外声明，则被认为是全局变量，可以在整个包甚至外部包（被导出后）使用，不管你声明在哪个源文件里或在哪个源文件里调用该变量。 在函数体内声明的变量称之为局部变量，它们的作用域只在函数体内，参数和返回值变量也是局部变量。 值类型和引用类型程序中所用到的内存在计算机中使用一堆箱子来表示，这些箱子被称为“字”。根据不同的处理器以及操作系统类型，所有的字都具有32位（4字节）和64位（8字节）的相同长度；所有的字都使用相关的内存地址来进行表示。 所有像int、float、bool和string这些基本类型都属于值类型，使用这些类型的变量直接指向存在内存中的值。 另外，像数组和结构这些复合类型也是值类型。 当使用等号=将一个变量的值赋值给另一个变量时，如：j=i，实际上是在内存中将i的值进行了拷贝。 你可以通过&amp;i来获取i的内存地址，例如：0xf840000040（每次的地址都可能不一样）。值类型的变量的值存储在栈中。 内存地址会根据机器的不同而有所不同，甚至相同的程序在不同的机器上执行后也会有不同的内存地址。因为每台机器可能有不同的存储器布局，并且位置分配也不同。 更复杂的数据通常会需要使用多个字，这些数据一般使用引用类型保存。 一个引用类型的变量r1存储的是r1的值所在的内存地址，或内存地址中第一个字所在的位置。 这个内存地址被称之为指针，这个指针实际上也被存在另外的某一个字中。 同一个引用类型的指针指向的多个字可以是在连续的内存地址中，这也是计算效率最高的一种存储形式；也可以将这些字分散存放在内存中，每个字都指示了下一个子所在的内存地址。 当使用赋值语句r2=r1时，只有引用（地址）被复制。 如果r1的值被改变了，那么这个值的所有饮用都会指向被修改后的内容，在这个例子中r2也会受到影响。 在Go语言中，指针属于引用类型，其它的引用类型还包括slices，maps和channel。被引用的变量会存在堆中，以便进行垃圾回收，且比栈拥有更大的内存空间。 简短形式，使用:=赋值操作符我们知道可以在变量的初始化时省略变量的类型而由系统自动推断。 这是使用变量的首选形式，但是它只能被用在函数体内，而不可以用于全局变量的声明与赋值。使用操作符:=可以高效地创建一个新的变量，称之为初始化声明。 多变量可以在同一行进行赋值，如： 1a,b,c:&#x3D;5,7,&quot;abc&quot; 右边的这些值以相同的顺序赋值给左边的变量，所以a的值是5，b的值是7，c的值是&quot;abc&quot;。 这些成为并行或同时赋值。 空白标识符_也被用于抛弃值，如值5在：_,b=5,7中被抛弃。 init 函数变量除了可以在全局声明中初始化，也可以在init函数中初始化。这是一类非常特殊的函数，它不能够被人为调用，而是在每个包完成初始化后自动执行，并且执行优先级比main函数高。 每个源文件都只能包含一个init函数。初始化总是以单线程执行，并且按照包的依赖关系顺序执行。 一个可能的用途是在开始执行程序之前对数据进行检验或修复，以保证程序状态的正确性。","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"基本结构和基本数据类型","slug":"基本结构和基本数据类型","permalink":"https://logan-liang.github.io/study/tags/%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"}]},{"title":"常量","slug":"one-basic-03","date":"2021-03-07T10:27:14.000Z","updated":"2022-07-05T01:32:17.176Z","comments":true,"path":"2021/03/07/one-basic-03/","link":"","permalink":"https://logan-liang.github.io/study/2021/03/07/one-basic-03/","excerpt":"","text":"常量使用const定义，用于存储不会改变的数据。 存储常量中的数据类型只可以是布尔型、数字型和字符串型。 常量的定义格式为：const identifier [type]=value，例如： const Pi=3.1415926 在Go语言中，你可以省略类型说明符[type]，因为编译器可以根据变量的值来推断其类型。 · 显示类型定义： `const b string = &quot;abc&quot;` · 隐式类型定义： `const b = &quot;abc&quot;` 常量的值必须是能够在编译时能购确定的；你可以在其赋值表达式中涉及计算过程，但是所有用于计算的值必须在编译期间就能获得。 因为编译期间自定义函数均属于未知，因此无法用于常量的赋值，但内置函数可以使用，如：len()。","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"基本结构和基本数据类型","slug":"基本结构和基本数据类型","permalink":"https://logan-liang.github.io/study/tags/%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"}]},{"title":"基本结构和要素","slug":"one-basic-02","date":"2021-03-06T10:46:17.000Z","updated":"2022-07-05T01:32:10.555Z","comments":true,"path":"2021/03/06/one-basic-02/","link":"","permalink":"https://logan-liang.github.io/study/2021/03/06/one-basic-02/","excerpt":"","text":"Quick Start包的概念、导入与可见性包是结构化代码的一种方式：买个程序都由包（pkg）的概念组成，可以使用自身的包或者从其它包中导入内容。每个Go文件都属于且仅属于一个包。一个包可以由许多以.go为扩展名的源文件组成，因此文件名和包名来说一般都是不相同的。 你必须在源文件中非注释的第一行指明这个文件属于哪个包，如package main。其表示一个可独立执行的程序，每个Go程序都包含一个名为main的包。 标准库在Go的安装文件里包含了一些可以直接使用的包，即标准库。在windows下，标准库的位置在Go根目录下的子目录pkg\\windows_386中；在Linux下，标准库在Go根目录下的子目录pkg\\linux_amd64中。一般情况下，标准包会存放在$GOROOT/pkg/$GOOS_$GOARCH/目录下。 Go 的标准库包含了大量的包（如：fmt 和 os），但是你也可以创建自己的包（第 9 章）。 如果想要构建一个程序，则包和包内的文件都必须以正确的顺序进行编译。包的依赖关系决定了其构建顺序。 属于同一个包的源文件必须全部被一起编译，一个包即是编译时的一个单元，因此根据惯例，每个目录都只包含一个包。 如果对一个包进行更改或重新编译，所有引用了这个包的客户端程序都必须全部重新编译。 Go 中的包模型采用了显式依赖关系的机制来达到快速编译的目的，编译器会从后缀名为 .o 的对象文件（需要且只需要这个文件）中提取传递依赖类型的信息。 如果 A.go 依赖 B.go，而 B.go 又依赖 C.go： 编译 C.go, B.go, 然后是 A.go. 为了编译 A.go, 编译器读取的是 B.o 而不是 C.o. 这种机制对于编译大型的项目时可以显著地提升编译速度。 函数这是定义一个函数最简单的格式： func funcName() 你可以在括号 () 中写入 0 个或多个函数的参数（使用逗号 , 分隔），每个参数的名称后面必须紧跟着该参数的类型。 main 函数是每一个可执行程序所必须包含的，一般来说都是在启动后第一个执行的函数（如果有 init() 函数则会先执行该函数）。如果你的 main 包的源代码没有包含 main 函数，则会引发构建错误 undefined: main.main。main 函数既没有参数，也没有返回类型（与 C 家族中的其它语言恰好相反）。如果你不小心为 main 函数添加了参数或者返回类型，将会引发构建错误 注释- 单行注释 `//我是注释` - 多行注释 `/*我是注释*/` 类型- 基本类型：`int,float,bool,string` - 结构化类型：`struct,array,slice,map,channel` - 描述类型：`interface` 相关知识，部分章节会详细讲解","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"基本结构和基本数据类型","slug":"基本结构和基本数据类型","permalink":"https://logan-liang.github.io/study/tags/%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"}]},{"title":"文件名、关键字与标识符","slug":"one-basic-01","date":"2021-03-06T10:11:03.000Z","updated":"2022-07-05T01:32:02.704Z","comments":true,"path":"2021/03/06/one-basic-01/","link":"","permalink":"https://logan-liang.github.io/study/2021/03/06/one-basic-01/","excerpt":"","text":"Quick Start文件名Go的源文件以 .go为后缀名存储在计算机中，这些文件名均由小写字母组成。如果文件名由多个部分组成，则使用下划线_对它们进行分隔，如scan_test.go。文件名不包含空格或其它特殊字符。 一个源文件可以包含任意多行代码，Go本身没有对源文件的大小进行限制。 标识符你会发现在Go代码中的几乎所有东西都有一个名称或标识符。另外，Go语言也是区分大小写的。有效的标识符必须以字母开头，然后紧跟着0个或多个字符或Unicode数字，如X56、group1。 以下是无效的标识符： - 1ab（以数字开头） - case （语言关键字） - a+b （运算符是不允许的） _ 本身就是一个特殊标识符，被称为空白标识符。 以下为Go语言36个预定义的标识符： append bool byte cap close complex complex64 complex128 uint16 copy false float32 float64 imag int int8 int16 uint32 int32 int64 iota len make new nil panic print println real recover string true uint new uint8 uintptr 程序中可能会使用到这些分隔符：括号 ()，中括号 [] 和大括号 &#123;&#125;。 程序中可能会使用到这些标点符号：.、,、;、: 和 …。 关键字Go 代码中会使用的25个关键字或保留字如下： break default func interface select case defer go map struct chan else goto package switch const fallthrough if range type continue for import return var","categories":[{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"}],"tags":[{"name":"基本结构和基本数据类型","slug":"基本结构和基本数据类型","permalink":"https://logan-liang.github.io/study/tags/%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"}]}],"categories":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://logan-liang.github.io/study/categories/Kubernetes/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://logan-liang.github.io/study/categories/RabbitMQ/"},{"name":"Git","slug":"Git","permalink":"https://logan-liang.github.io/study/categories/Git/"},{"name":"Golang","slug":"Golang","permalink":"https://logan-liang.github.io/study/categories/Golang/"},{"name":"Redis","slug":"Redis","permalink":"https://logan-liang.github.io/study/categories/Redis/"},{"name":"MySQL","slug":"MySQL","permalink":"https://logan-liang.github.io/study/categories/MySQL/"},{"name":"GraphQL","slug":"GraphQL","permalink":"https://logan-liang.github.io/study/categories/GraphQL/"}],"tags":[{"name":"k8s-资源对象","slug":"k8s-资源对象","permalink":"https://logan-liang.github.io/study/tags/k8s-%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1/"},{"name":"k8s-核心组件","slug":"k8s-核心组件","permalink":"https://logan-liang.github.io/study/tags/k8s-%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"},{"name":"RabbitMQ-数据丢失","slug":"RabbitMQ-数据丢失","permalink":"https://logan-liang.github.io/study/tags/RabbitMQ-%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1/"},{"name":"RabbitMQ-延时队列","slug":"RabbitMQ-延时队列","permalink":"https://logan-liang.github.io/study/tags/RabbitMQ-%E5%BB%B6%E6%97%B6%E9%98%9F%E5%88%97/"},{"name":"RabbitMQ-交换机","slug":"RabbitMQ-交换机","permalink":"https://logan-liang.github.io/study/tags/RabbitMQ-%E4%BA%A4%E6%8D%A2%E6%9C%BA/"},{"name":"Command","slug":"Command","permalink":"https://logan-liang.github.io/study/tags/Command/"},{"name":"Rebase","slug":"Rebase","permalink":"https://logan-liang.github.io/study/tags/Rebase/"},{"name":"GC","slug":"GC","permalink":"https://logan-liang.github.io/study/tags/GC/"},{"name":"CSP","slug":"CSP","permalink":"https://logan-liang.github.io/study/tags/CSP/"},{"name":"Context","slug":"Context","permalink":"https://logan-liang.github.io/study/tags/Context/"},{"name":"Channel","slug":"Channel","permalink":"https://logan-liang.github.io/study/tags/Channel/"},{"name":"Redis-缓存","slug":"Redis-缓存","permalink":"https://logan-liang.github.io/study/tags/Redis-%E7%BC%93%E5%AD%98/"},{"name":"Redis-持久化","slug":"Redis-持久化","permalink":"https://logan-liang.github.io/study/tags/Redis-%E6%8C%81%E4%B9%85%E5%8C%96/"},{"name":"Redis-淘汰机制","slug":"Redis-淘汰机制","permalink":"https://logan-liang.github.io/study/tags/Redis-%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6/"},{"name":"Redis-分布式锁","slug":"Redis-分布式锁","permalink":"https://logan-liang.github.io/study/tags/Redis-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"name":"Redis-数据类型","slug":"Redis-数据类型","permalink":"https://logan-liang.github.io/study/tags/Redis-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"},{"name":"MySQL缓存","slug":"MySQL缓存","permalink":"https://logan-liang.github.io/study/tags/MySQL%E7%BC%93%E5%AD%98/"},{"name":"MySQL通信过程","slug":"MySQL通信过程","permalink":"https://logan-liang.github.io/study/tags/MySQL%E9%80%9A%E4%BF%A1%E8%BF%87%E7%A8%8B/"},{"name":"MySQL性能指标","slug":"MySQL性能指标","permalink":"https://logan-liang.github.io/study/tags/MySQL%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87/"},{"name":"MySQL插入","slug":"MySQL插入","permalink":"https://logan-liang.github.io/study/tags/MySQL%E6%8F%92%E5%85%A5/"},{"name":"MySQL索引","slug":"MySQL索引","permalink":"https://logan-liang.github.io/study/tags/MySQL%E7%B4%A2%E5%BC%95/"},{"name":"MySQL存储引擎","slug":"MySQL存储引擎","permalink":"https://logan-liang.github.io/study/tags/MySQL%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"},{"name":"MySQL锁","slug":"MySQL锁","permalink":"https://logan-liang.github.io/study/tags/MySQL%E9%94%81/"},{"name":"MySQL事务","slug":"MySQL事务","permalink":"https://logan-liang.github.io/study/tags/MySQL%E4%BA%8B%E5%8A%A1/"},{"name":"锁的应用","slug":"锁的应用","permalink":"https://logan-liang.github.io/study/tags/%E9%94%81%E7%9A%84%E5%BA%94%E7%94%A8/"},{"name":"GraphQL 入门","slug":"GraphQL-入门","permalink":"https://logan-liang.github.io/study/tags/GraphQL-%E5%85%A5%E9%97%A8/"},{"name":"性能调优","slug":"性能调优","permalink":"https://logan-liang.github.io/study/tags/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"},{"name":"内部包","slug":"内部包","permalink":"https://logan-liang.github.io/study/tags/%E5%86%85%E9%83%A8%E5%8C%85/"},{"name":"数组与切片","slug":"数组与切片","permalink":"https://logan-liang.github.io/study/tags/%E6%95%B0%E7%BB%84%E4%B8%8E%E5%88%87%E7%89%87/"},{"name":"函数","slug":"函数","permalink":"https://logan-liang.github.io/study/tags/%E5%87%BD%E6%95%B0/"},{"name":"控制结构","slug":"控制结构","permalink":"https://logan-liang.github.io/study/tags/%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84/"},{"name":"基本结构和基本数据类型","slug":"基本结构和基本数据类型","permalink":"https://logan-liang.github.io/study/tags/%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"}]}